{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parser design using pydantic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the string content from the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.responses import JSONResponse\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "async def read_file_content(file: UploadFile) -> str:\n",
    "    \"\"\"\n",
    "    Read and return the content of various file types uploaded via FastAPI.\n",
    "    \n",
    "    :param file: UploadFile object from FastAPI\n",
    "    :return: Content of the file as a string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        content = await file.read()\n",
    "        content_str = content.decode()\n",
    "\n",
    "        # Determine file type based on filename\n",
    "        file_extension = file.filename.split('.')[-1].lower()\n",
    "\n",
    "        if file_extension == 'json':\n",
    "            # Parse JSON and format it\n",
    "            parsed = json.loads(content_str)\n",
    "            return json.dumps(parsed, indent=2)\n",
    "        \n",
    "        elif file_extension == 'xml':\n",
    "            # Parse XML and format it\n",
    "            root = ET.fromstring(content_str)\n",
    "            return ET.tostring(root, encoding='unicode', method='xml')\n",
    "        \n",
    "        elif file_extension == 'html':\n",
    "            # Parse HTML and format it\n",
    "            soup = BeautifulSoup(content_str, 'html.parser')\n",
    "            return soup.prettify()\n",
    "        \n",
    "        else:\n",
    "            # For other file types (including .txt), return content as is\n",
    "            return content_str\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        raise HTTPException(status_code=400, detail=\"Invalid JSON file\")\n",
    "    except ET.ParseError:\n",
    "        raise HTTPException(status_code=400, detail=\"Invalid XML file\")\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Error reading file: {str(e)}\")\n",
    "\n",
    "@app.post(\"/upload/\")\n",
    "async def upload_file(file: UploadFile = File(...)):\n",
    "    content = await read_file_content(file)\n",
    "    return JSONResponse(content={\"filename\": file.filename, \"content\": content})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting the input type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from azure.openai import AzureOpenAI\n",
    "import os\n",
    "\n",
    "# Azure OpenAI setup\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "class InputTypeResponse(BaseModel):\n",
    "    input_type: Literal['html', 'xml', 'json', 'markdown', 'yaml', 'csv', 'plaintext'] = Field(\n",
    "        ...,\n",
    "        description=\"The identified type of the input content\"\n",
    "    )\n",
    "\n",
    "class ContentAnalyzer:\n",
    "    def identify_input_type(self, content: str) -> str:\n",
    "        prompt = f\"\"\"\n",
    "        Analyze the following content and identify its type. Respond with a single word in lowercase, choosing from:\n",
    "        - html\n",
    "        - xml\n",
    "        - json\n",
    "        - markdown\n",
    "        - yaml\n",
    "        - csv\n",
    "        - plaintext\n",
    "\n",
    "        Use 'plaintext' if the content doesn't match any specific format.\n",
    "        \n",
    "        Guidelines:\n",
    "        - Look for distinctive markers like HTML tags, XML declarations, JSON brackets, or Markdown syntax.\n",
    "        - Consider structure and formatting, not just the presence of certain characters.\n",
    "        - If multiple formats are present, choose the predominant one.\n",
    "\n",
    "        Content: {content[:500]}\n",
    "\n",
    "        Respond only with the type, nothing else.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a content type analyzer.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "                response_format=InputTypeResponse\n",
    "            )\n",
    "            \n",
    "            return completion.choices[0].message.input_type\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {str(e)}\")\n",
    "            return \"unknown\"\n",
    "\n",
    "# Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     analyzer = ContentAnalyzer()\n",
    "    \n",
    "#     test_contents = [\n",
    "#         \"<html><body><h1>Hello</h1></body></html>\",\n",
    "#         \"<?xml version='1.0'?><root><element>Content</element></root>\",\n",
    "#         '{\"key\": \"value\", \"array\": [1, 2, 3]}',\n",
    "#         \"# Markdown Header\\n\\nThis is some markdown content.\",\n",
    "#         \"key: value\\nnested:\\n  subkey: subvalue\",\n",
    "#         \"column1,column2,column3\\nvalue1,value2,value3\",\n",
    "#         \"Just some plain text content.\"\n",
    "#     ]\n",
    "\n",
    "#     for content in test_contents:\n",
    "#         input_type = analyzer.identify_input_type(content)\n",
    "#         print(f\"Identified type: {input_type}\")\n",
    "#         print(f\"For content: {content[:50]}...\")\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the translatable content from the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Union\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from azure.openai import AzureOpenAI\n",
    "import os\n",
    "\n",
    "# Azure OpenAI settings\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=azure_endpoint\n",
    ")\n",
    "\n",
    "# class Metadata(BaseModel):\n",
    "#     tag: str = None\n",
    "#     attributes: str = None\n",
    "#     formatting: str = None\n",
    "\n",
    "# class TranslatableElement(BaseModel):\n",
    "#     type: str\n",
    "#     content: str\n",
    "#     metadata: Metadata = None\n",
    "#     non_translatable: List[str] = Field(default_factory=list)\n",
    "\n",
    "# class TranslatableContent(BaseModel):\n",
    "#     elements: List[TranslatableElement]\n",
    "\n",
    "class Metadata(BaseModel):\n",
    "    tag: Optional[str] = Field(None, description=\"Structural identifier for the content element\")\n",
    "    attributes: Optional[str] = Field(None, description=\"Additional properties or characteristics of the content element\")\n",
    "    formatting: Optional[str] = Field(None, description=\"Styling or layout information for the content\")\n",
    "\n",
    "class TranslatableElement(BaseModel):\n",
    "    type: str = Field(..., description=\"Category or classification of the content element\")\n",
    "    content: str = Field(..., description=\"The actual text or data to be translated\")\n",
    "    metadata: Optional[Metadata] = Field(None, description=\"Supplementary information about the content structure and formatting\")\n",
    "    non_translatable: List[str] = Field(default_factory=list, description=\"Terms or phrases that should remain in their original form\")\n",
    "\n",
    "class TranslatableContent(BaseModel):\n",
    "    elements: List[TranslatableElement] = Field(..., description=\"Collection of translatable components extracted from the input\")\n",
    "\n",
    "def extract_translatable_content(content: str, input_type: str) -> List[Dict[str, Union[str, List[str]]]]:\n",
    "    prompt = f\"\"\"\n",
    "        Analyze and extract the translatable content from the following {input_type} input.\n",
    "        Return the content as a structured list of elements, where each element represents a translatable item.\n",
    "\n",
    "        Rules:\n",
    "        1. Preserve the structure of the original {input_type} input.\n",
    "        2. Identify and mark domain-specific terms or technical jargon as non-translatable.\n",
    "        3. Include relevant metadata to aid in reconstructing the original format after translation.\n",
    "        4. For plain text input, use \"paragraph\" as the type and omit the metadata.\n",
    "\n",
    "        Input: {content}\n",
    "\n",
    "        Ensure the output follows the structure defined in the TranslatableContent model.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment_name,  # Use the deployment name here\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that extracts translatable content from various input types.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            response_format=TranslatableContent\n",
    "        )\n",
    "        \n",
    "        return [element.model_dump(exclude_none=True) for element in completion.choices[0].message.elements]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def extract_content(data):\n",
    "    \"\"\"\n",
    "    Extract only the 'content' field from the input data.\n",
    "\n",
    "    Args:\n",
    "    data (list): A list of dictionaries, each containing a 'content' key.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of strings, each string being the 'content' value.\n",
    "    \"\"\"\n",
    "    return [item['content'] for item in data]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# html_input = \"<h1>Welcome to Azure</h1><p>This is a cloud service.</p>\"\n",
    "# result = extract_translatable_content(html_input, \"HTML\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Translation rules from JSON files for translatable content extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict, Union\n",
    "from pydantic import BaseModel, Field\n",
    "# from azure.openai import AzureOpenAI\n",
    "from typing import List, Optional\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Azure OpenAI settings\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "client = openai(\n",
    "    api_key=api_key,\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=azure_endpoint\n",
    ")\n",
    "\n",
    "# class Metadata(BaseModel):\n",
    "#     tag: str = None\n",
    "#     attributes: str = None\n",
    "#     formatting: str = None\n",
    "\n",
    "# class TranslatableElement(BaseModel):\n",
    "#     type: str\n",
    "#     content: str\n",
    "#     metadata: Metadata = None\n",
    "#     non_translatable: List[str] = Field(default_factory=list)\n",
    "\n",
    "# class TranslatableContent(BaseModel):\n",
    "#     elements: List[TranslatableElement]\n",
    "\n",
    "class Metadata(BaseModel):\n",
    "    tag: Optional[str] = Field(None, description=\"Structural identifier for the content element\")\n",
    "    attributes: Optional[str] = Field(None, description=\"Additional properties or characteristics of the content element\")\n",
    "    formatting: Optional[str] = Field(None, description=\"Styling or layout information for the content\")\n",
    "\n",
    "class TranslatableElement(BaseModel):\n",
    "    type: str = Field(..., description=\"Category or classification of the content element\")\n",
    "    content: str = Field(..., description=\"The actual text or data to be translated\")\n",
    "    metadata: Optional[Metadata] = Field(None, description=\"Supplementary information about the content structure and formatting\")\n",
    "    non_translatable: List[str] = Field(default_factory=list, description=\"Terms or phrases that should remain in their original form\")\n",
    "\n",
    "class TranslatableContent(BaseModel):\n",
    "    elements: List[TranslatableElement] = Field(..., description=\"Collection of translatable components extracted from the input\")\n",
    "\n",
    "def load_rules(file_path: str = 'translation_rules.json') -> Dict:\n",
    "    \"\"\"Load translation rules from a JSON file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Rules file not found: {file_path}\")\n",
    "        return {}\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Invalid JSON in rules file: {file_path}\")\n",
    "        return {}\n",
    "\n",
    "def extract_translatable_content(content: str, input_type: str) -> List[Dict[str, Union[str, List[str]]]]:\n",
    "    # Load rules\n",
    "    rules = load_rules()\n",
    "    \n",
    "    # Construct prompt with loaded rules\n",
    "    rules_text = \"\\n\".join(rules.get('extraction_rules', []))\n",
    "    prompt = f\"\"\"\n",
    "        Analyze and extract the translatable content from the following {input_type} input.\n",
    "        Return the content as a structured list of elements, where each element represents a translatable item.\n",
    "\n",
    "        Rules:\n",
    "        {rules_text}\n",
    "\n",
    "        Additional instructions:\n",
    "        1. Preserve the structure of the original {input_type} input.\n",
    "        2. Include relevant metadata to aid in reconstructing the original format after translation.\n",
    "        3. For plain text input, use \"paragraph\" as the type and omit the metadata.\n",
    "\n",
    "        Input: {content}\n",
    "\n",
    "        Ensure the output follows the structure defined in the TranslatableContent model.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        completion = openai.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that extracts translatable content from various input types based on certain given rules.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            response_format=TranslatableContent\n",
    "        )\n",
    "        \n",
    "        return [element.model_dump(exclude_none=True) for element in completion.choices[0].message.elements]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     html_input = \"<h1>Welcome to Azure</h1><p>This is a cloud service.</p>\"\n",
    "#     result = extract_translatable_content(html_input, \"HTML\")\n",
    "#     print(result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_content(data):\n",
    "    \"\"\"\n",
    "    Extract only the 'content' field from the input data.\n",
    "\n",
    "    Args:\n",
    "    data (list): A list of dictionaries, each containing a 'content' key.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of strings, each string being the 'content' value.\n",
    "    \"\"\"\n",
    "    return [item['content'] for item in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstructing the original input type from the translated content and saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Union\n",
    "from azure.openai import AzureOpenAI\n",
    "import os\n",
    "\n",
    "# Azure OpenAI setup\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "class ReconstructedContent(BaseModel):\n",
    "    content: str = Field(..., description=\"The reconstructed content in its original format\")\n",
    "    input_type: str = Field(..., description=\"The type of the input/output content (e.g., 'html', 'xml', 'json')\")\n",
    "\n",
    "class ContentReconstructor:\n",
    "    def reconstruct_output(\n",
    "        self, \n",
    "        original_content: str, \n",
    "        extracted_structure: List[Dict[str, Union[str, List[str]]]], \n",
    "        translated_content: List[str], \n",
    "        input_type: str\n",
    "    ) -> str:\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        Reconstruct the original {input_type} format using the translated content and extracted structure.\n",
    "\n",
    "        Original content: \n",
    "        {original_content} \n",
    "\n",
    "        Extracted structure:\n",
    "        {extracted_structure}\n",
    "\n",
    "        Translated content (in order of extraction):\n",
    "        {translated_content}\n",
    "\n",
    "        Instructions:\n",
    "        1. Use the extracted structure to guide the reconstruction process.\n",
    "        2. Replace the original text in each extracted element with the corresponding translated text.\n",
    "        3. Preserve all original formatting, tags, attributes, and non-translatable content.\n",
    "        4. Ensure that the reconstructed content maintains the same structure and order as the original.\n",
    "        5. For any domain-specific terms, technical terms or proper nouns that were marked as non-translatable, use the original text.\n",
    "        6. If there are any placeholders or variables in the original content, ensure they are correctly maintained in the translated version.\n",
    "\n",
    "        Return the fully reconstructed {input_type} content, ensuring it's a valid and well-formatted {input_type} document.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a content reconstruction specialist.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "                response_format=ReconstructedContent\n",
    "            )\n",
    "            \n",
    "            result = completion.choices[0].message\n",
    "            return result.content  # Return just the content string\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {str(e)}\")\n",
    "            return \"\"\n",
    "        \n",
    "        \n",
    "    def save_content_to_file(self, content: str, input_type: str, filename: str = None) -> str:\n",
    "        \"\"\"\n",
    "        Save the reconstructed content to a file with the appropriate extension.\n",
    "        \n",
    "        :param content: The content to be saved\n",
    "        :param input_type: The type of content (e.g., 'html', 'xml', 'json', 'plaintext')\n",
    "        :param filename: Optional custom filename (without extension)\n",
    "        :return: The path of the saved file\n",
    "        \"\"\"\n",
    "        # Map input types to file extensions\n",
    "        extension_map = {\n",
    "            \"html\": \"html\",\n",
    "            \"xml\": \"xml\",\n",
    "            \"json\": \"json\",\n",
    "            \"plaintext\": \"txt\",\n",
    "            \"text\": \"txt\",\n",
    "            \"txt\": \"txt\"\n",
    "        }\n",
    "        \n",
    "        # Get the appropriate extension, defaulting to 'txt' if not found\n",
    "        extension = extension_map.get(input_type.lower(), \"txt\")\n",
    "        \n",
    "        if filename is None:\n",
    "            filename = f\"reconstructed_content_{input_type}\"\n",
    "        \n",
    "        # Ensure the filename doesn't already have the extension\n",
    "        if not filename.endswith(f\".{extension}\"):\n",
    "            full_filename = f\"{filename}.{extension}\"\n",
    "        else:\n",
    "            full_filename = filename\n",
    "        \n",
    "        try:\n",
    "            with open(full_filename, 'w', encoding='utf-8') as file:\n",
    "                file.write(content)\n",
    "            print(f\"Content saved successfully to {full_filename}\")\n",
    "            return full_filename\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving file: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "# Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     reconstructor = ContentReconstructor()\n",
    "    \n",
    "    # Example inputs (you would replace these with your actual data)\n",
    "    # original_content = \"<html><body><h1>Hello</h1><p>World</p></body></html>\"\n",
    "    # extracted_structure = [\n",
    "    #     {\"type\": \"heading\", \"content\": \"Hello\", \"metadata\": {\"tag\": \"h1\"}},\n",
    "    #     {\"type\": \"paragraph\", \"content\": \"World\", \"metadata\": {\"tag\": \"p\"}}\n",
    "    # ]\n",
    "    # translated_content = [\"Bonjour\", \"le monde\"]\n",
    "    # input_type = \"html\"\n",
    "\n",
    "    # reconstructed = reconstructor.reconstruct_output(\n",
    "    #     original_content, \n",
    "    #     extracted_structure, \n",
    "    #     translated_content, \n",
    "    #     input_type\n",
    "    # )\n",
    "\n",
    "    # print(\"Reconstructed content:\")\n",
    "    # print(reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import xml.etree.ElementTree as ET\n",
    "# from bs4 import BeautifulSoup\n",
    "# import chardet\n",
    "\n",
    "# def read_file_content(file_path: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Read and return the content of various file types.\n",
    "    \n",
    "#     :param file_path: Path to the file\n",
    "#     :return: Content of the file as a string\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Detect the file encoding\n",
    "#         with open(file_path, 'rb') as file:\n",
    "#             raw_data = file.read()\n",
    "#             detected = chardet.detect(raw_data)\n",
    "#             encoding = detected['encoding']\n",
    "\n",
    "#         # Read the file content using the detected encoding\n",
    "#         with open(file_path, 'r', encoding=encoding) as file:\n",
    "#             content = file.read()\n",
    "\n",
    "#         # Determine file type based on extension\n",
    "#         file_extension = file_path.split('.')[-1].lower()\n",
    "\n",
    "#         if file_extension == 'json':\n",
    "#             # Parse JSON and format it\n",
    "#             parsed = json.loads(content)\n",
    "#             return json.dumps(parsed, indent=2)\n",
    "        \n",
    "#         elif file_extension == 'xml':\n",
    "#             # Parse XML and format it\n",
    "#             root = ET.fromstring(content)\n",
    "#             return ET.tostring(root, encoding='unicode', method='xml')\n",
    "        \n",
    "#         elif file_extension == 'html':\n",
    "#             # Parse HTML and format it\n",
    "#             soup = BeautifulSoup(content, 'html.parser')\n",
    "#             return soup.prettify()\n",
    "        \n",
    "#         else:\n",
    "#             # For other file types (including .txt), return content as is\n",
    "#             return content\n",
    "\n",
    "#     except json.JSONDecodeError:\n",
    "#         return \"Error: Invalid JSON file\"\n",
    "#     except ET.ParseError:\n",
    "#         return \"Error: Invalid XML file\"\n",
    "#     except Exception as e:\n",
    "#         return f\"Error reading file: {str(e)}\"\n",
    "\n",
    "# # Example usage\n",
    "# file_types = ['html', 'xml', 'json', 'txt']\n",
    "# for file_type in file_types:\n",
    "#     file_path = f\"example.{file_type}\"\n",
    "#     content = read_file_content(file_path)\n",
    "#     print(f\"\\nContent of {file_path}:\")\n",
    "#     print(content[:200] + \"...\" if len(content) > 200 else content)  # Print first 200 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "# from fastapi.responses import JSONResponse\n",
    "# import json\n",
    "# import xml.etree.ElementTree as ET\n",
    "# from bs4 import BeautifulSoup\n",
    "# import io\n",
    "\n",
    "# app = FastAPI()\n",
    "\n",
    "# async def read_file_content(file: UploadFile) -> str:\n",
    "#     \"\"\"\n",
    "#     Read and return the content of various file types uploaded via FastAPI.\n",
    "    \n",
    "#     :param file: UploadFile object from FastAPI\n",
    "#     :return: Content of the file as a string\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         content = await file.read()\n",
    "#         content_str = content.decode()\n",
    "\n",
    "#         # Determine file type based on filename\n",
    "#         file_extension = file.filename.split('.')[-1].lower()\n",
    "\n",
    "#         if file_extension == 'json':\n",
    "#             # Parse JSON and format it\n",
    "#             parsed = json.loads(content_str)\n",
    "#             return json.dumps(parsed, indent=2)\n",
    "        \n",
    "#         elif file_extension == 'xml':\n",
    "#             # Parse XML and format it\n",
    "#             root = ET.fromstring(content_str)\n",
    "#             return ET.tostring(root, encoding='unicode', method='xml')\n",
    "        \n",
    "#         elif file_extension == 'html':\n",
    "#             # Parse HTML and format it\n",
    "#             soup = BeautifulSoup(content_str, 'html.parser')\n",
    "#             return soup.prettify()\n",
    "        \n",
    "#         else:\n",
    "#             # For other file types (including .txt), return content as is\n",
    "#             return content_str\n",
    "\n",
    "#     except json.JSONDecodeError:\n",
    "#         raise HTTPException(status_code=400, detail=\"Invalid JSON file\")\n",
    "#     except ET.ParseError:\n",
    "#         raise HTTPException(status_code=400, detail=\"Invalid XML file\")\n",
    "#     except Exception as e:\n",
    "#         raise HTTPException(status_code=500, detail=f\"Error reading file: {str(e)}\")\n",
    "\n",
    "# @app.post(\"/upload/\")\n",
    "# async def upload_file(file: UploadFile = File(...)):\n",
    "#     content = await read_file_content(file)\n",
    "#     return JSONResponse(content={\"filename\": file.filename, \"content\": content})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
