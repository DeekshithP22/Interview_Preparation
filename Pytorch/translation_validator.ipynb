{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: format_validator.py\n",
    "import json\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "import xmldiff.main\n",
    "import jsonschema\n",
    "import html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatValidator:\n",
    "    def __init__(self):\n",
    "        self.errors = []\n",
    "        self.suggestions = []\n",
    "\n",
    "    def validate(self, original_content, reconstructed_content, format_type):\n",
    "        self.errors = []\n",
    "        self.suggestions = []\n",
    "        \n",
    "        if format_type == 'html':\n",
    "            return self._validate_html(original_content, reconstructed_content)\n",
    "        elif format_type == 'json':\n",
    "            return self._validate_json(original_content, reconstructed_content)\n",
    "        elif format_type == 'xml':\n",
    "            return self._validate_xml(original_content, reconstructed_content)\n",
    "        else:\n",
    "            self.errors.append(f\"Unsupported format: {format_type}\")\n",
    "            return False\n",
    "\n",
    "    def _validate_html(self, original_html, reconstructed_html):\n",
    "        original_soup = BeautifulSoup(original_html, 'html5lib')\n",
    "        reconstructed_soup = BeautifulSoup(reconstructed_html, 'html5lib')\n",
    "\n",
    "        # Check 1: Basic HTML parsing\n",
    "        if original_soup.find() is None:\n",
    "            self.errors.append(\"Original HTML is not parseable\")\n",
    "            return False\n",
    "        if reconstructed_soup.find() is None:\n",
    "            self.errors.append(\"Reconstructed HTML is not parseable\")\n",
    "            self.suggestions.append(\"Ensure the reconstructed HTML has a valid structure with proper opening and closing tags.\")\n",
    "            return False\n",
    "\n",
    "        # Check 2: Compare tag counts\n",
    "        original_tags = Counter(tag.name for tag in original_soup.find_all())\n",
    "        reconstructed_tags = Counter(tag.name for tag in reconstructed_soup.find_all())\n",
    "        if original_tags != reconstructed_tags:\n",
    "            self.errors.append(\"Tag count mismatch\")\n",
    "            self.suggestions.append(f\"Adjust the number of HTML tags to match the original. Original counts: {dict(original_tags)}, Reconstructed counts: {dict(reconstructed_tags)}\")\n",
    "\n",
    "        # Check 3: Structure comparison\n",
    "        if not self._compare_html_structure(original_soup, reconstructed_soup):\n",
    "            self.errors.append(\"Overall HTML structure mismatch\")\n",
    "            self.suggestions.append(\"Ensure the hierarchical structure of HTML elements matches the original.\")\n",
    "\n",
    "        # Check 4: Attribute preservation\n",
    "        if not self._compare_html_attributes(original_soup, reconstructed_soup):\n",
    "            self.errors.append(\"HTML attribute mismatch\")\n",
    "            self.suggestions.append(\"Preserve all original HTML attributes, including their values.\")\n",
    "\n",
    "        # Check 5: Content length comparison\n",
    "        original_content_length = len(original_soup.get_text())\n",
    "        reconstructed_content_length = len(reconstructed_soup.get_text())\n",
    "        if abs(original_content_length - reconstructed_content_length) > original_content_length * 0.2:  # 20% tolerance\n",
    "            self.errors.append(\"Significant content length difference\")\n",
    "            self.suggestions.append(f\"Adjust the content length to be within 20% of the original. Original length: {original_content_length}, Reconstructed length: {reconstructed_content_length}\")\n",
    "\n",
    "        return len(self.errors) == 0\n",
    "\n",
    "    def _validate_json(self, original_json, reconstructed_json):\n",
    "        try:\n",
    "            original_dict = json.loads(original_json)\n",
    "            reconstructed_dict = json.loads(reconstructed_json)\n",
    "        except json.JSONDecodeError as e:\n",
    "            self.errors.append(f\"Invalid JSON format: {str(e)}\")\n",
    "            self.suggestions.append(\"Ensure the JSON is properly formatted with correct syntax.\")\n",
    "            return False\n",
    "\n",
    "        # Check 1: Schema validation\n",
    "        schema = self._generate_json_schema(original_dict)\n",
    "        try:\n",
    "            jsonschema.validate(instance=reconstructed_dict, schema=schema)\n",
    "        except jsonschema.exceptions.ValidationError as ve:\n",
    "            self.errors.append(f\"JSON schema validation failed: {ve}\")\n",
    "            self.suggestions.append(\"Adjust the JSON structure to match the original schema.\")\n",
    "            return False\n",
    "\n",
    "        # Check 2: Structure comparison\n",
    "        if not self._compare_json_structure(original_dict, reconstructed_dict):\n",
    "            self.errors.append(\"JSON structure mismatch\")\n",
    "            self.suggestions.append(\"Ensure all keys and nested structures in the JSON match the original.\")\n",
    "\n",
    "        # Check 3: Value type preservation\n",
    "        type_mismatches = self._check_json_value_types(original_dict, reconstructed_dict)\n",
    "        if type_mismatches:\n",
    "            self.errors.append(\"JSON value type mismatch\")\n",
    "            self.suggestions.extend(type_mismatches)\n",
    "\n",
    "        return len(self.errors) == 0\n",
    "\n",
    "    def _validate_xml(self, original_xml, reconstructed_xml):\n",
    "        try:\n",
    "            original_root = ET.fromstring(original_xml)\n",
    "            reconstructed_root = ET.fromstring(reconstructed_xml)\n",
    "        except ET.ParseError as e:\n",
    "            self.errors.append(f\"Invalid XML format: {str(e)}\")\n",
    "            self.suggestions.append(\"Ensure the XML is well-formed with proper opening and closing tags.\")\n",
    "            return False\n",
    "\n",
    "        # Check 1: Structure comparison\n",
    "        diff = xmldiff.main.diff_trees(original_root, reconstructed_root)\n",
    "        if diff:\n",
    "            self.errors.append(\"XML structure mismatch\")\n",
    "            self.suggestions.append(\"Ensure the XML element structure and hierarchy match the original.\")\n",
    "\n",
    "        # Check 2: Attribute preservation\n",
    "        if not self._compare_xml_attributes(original_root, reconstructed_root):\n",
    "            self.errors.append(\"XML attributes mismatch\")\n",
    "            self.suggestions.append(\"Preserve all original XML attributes, including their values.\")\n",
    "\n",
    "        # Check 3: Element count\n",
    "        original_count = self._count_xml_elements(original_root)\n",
    "        reconstructed_count = self._count_xml_elements(reconstructed_root)\n",
    "        if original_count != reconstructed_count:\n",
    "            self.errors.append(\"XML element count mismatch\")\n",
    "            self.suggestions.append(f\"Adjust the number of XML elements to match the original. Original count: {original_count}, Reconstructed count: {reconstructed_count}\")\n",
    "\n",
    "        return len(self.errors) == 0\n",
    "\n",
    "    def _compare_html_structure(self, soup1, soup2):\n",
    "        def get_structure(soup):\n",
    "            return ''.join(element.name for element in soup.descendants if element.name)\n",
    "        return get_structure(soup1) == get_structure(soup2)\n",
    "\n",
    "    def _compare_html_attributes(self, soup1, soup2):\n",
    "        elements1 = soup1.find_all()\n",
    "        elements2 = soup2.find_all()\n",
    "        if len(elements1) != len(elements2):\n",
    "            return False\n",
    "        return all(e1.attrs == e2.attrs for e1, e2 in zip(elements1, elements2))\n",
    "\n",
    "    def _generate_json_schema(self, json_dict):\n",
    "        schema = {\"type\": \"object\", \"properties\": {}}\n",
    "        for key, value in json_dict.items():\n",
    "            if isinstance(value, dict):\n",
    "                schema[\"properties\"][key] = self._generate_json_schema(value)\n",
    "            elif isinstance(value, list):\n",
    "                schema[\"properties\"][key] = {\"type\": \"array\"}\n",
    "            else:\n",
    "                schema[\"properties\"][key] = {\"type\": type(value).__name__}\n",
    "        return schema\n",
    "\n",
    "    def _compare_json_structure(self, dict1, dict2):\n",
    "        if not isinstance(dict1, type(dict2)):\n",
    "            return False\n",
    "        if isinstance(dict1, dict):\n",
    "            return set(dict1.keys()) == set(dict2.keys()) and all(self._compare_json_structure(dict1[k], dict2[k]) for k in dict1)\n",
    "        if isinstance(dict1, list):\n",
    "            return len(dict1) == len(dict2) and all(self._compare_json_structure(v1, v2) for v1, v2 in zip(dict1, dict2))\n",
    "        return True\n",
    "\n",
    "    def _check_json_value_types(self, dict1, dict2, path=\"\"):\n",
    "        mismatches = []\n",
    "        if isinstance(dict1, dict):\n",
    "            for k in dict1:\n",
    "                new_path = f\"{path}.{k}\" if path else k\n",
    "                if k in dict2:\n",
    "                    mismatches.extend(self._check_json_value_types(dict1[k], dict2[k], new_path))\n",
    "                else:\n",
    "                    mismatches.append(f\"Missing key at {new_path}\")\n",
    "        elif isinstance(dict1, list):\n",
    "            if len(dict1) != len(dict2):\n",
    "                mismatches.append(f\"Array length mismatch at {path}\")\n",
    "            else:\n",
    "                for i, (v1, v2) in enumerate(zip(dict1, dict2)):\n",
    "                    mismatches.extend(self._check_json_value_types(v1, v2, f\"{path}[{i}]\"))\n",
    "        elif type(dict1) != type(dict2):\n",
    "            mismatches.append(f\"Type mismatch at {path}: expected {type(dict1).__name__}, got {type(dict2).__name__}\")\n",
    "        return mismatches\n",
    "\n",
    "    def _compare_xml_attributes(self, elem1, elem2):\n",
    "        if elem1.tag != elem2.tag:\n",
    "            return False\n",
    "        if elem1.attrib != elem2.attrib:\n",
    "            return False\n",
    "        if len(elem1) != len(elem2):\n",
    "            return False\n",
    "        return all(self._compare_xml_attributes(c1, c2) for c1, c2 in zip(elem1, elem2))\n",
    "\n",
    "    def _count_xml_elements(self, elem):\n",
    "        return 1 + sum(self._count_xml_elements(child) for child in elem)\n",
    "\n",
    "    def get_feedback(self):\n",
    "        return {\n",
    "            \"errors\": self.errors,\n",
    "            \"suggestions\": self.suggestions\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The 'left' and 'right' parameters must be lxml Elements.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m original_xml \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<root><person><name>John</name><age>30</age></person></root>\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     19\u001b[0m reconstructed_xml \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<root><person><name>Jean</name><age>30</age><city>Paris</city></person></root>\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mXML Validation:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mvalidator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_xml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreconstructed_xml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeedback:\u001b[39m\u001b[38;5;124m\"\u001b[39m, validator\u001b[38;5;241m.\u001b[39mget_feedback())\n",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m, in \u001b[0;36mFormatValidator.validate\u001b[1;34m(self, original_content, reconstructed_content, format_type)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_json(original_content, reconstructed_content)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m format_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxml\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_xml\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreconstructed_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformat_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 100\u001b[0m, in \u001b[0;36mFormatValidator._validate_xml\u001b[1;34m(self, original_xml, reconstructed_xml)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Check 1: Structure comparison\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m diff \u001b[38;5;241m=\u001b[39m \u001b[43mxmldiff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff_trees\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreconstructed_root\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXML structure mismatch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Interview_Preparation\\.venv\\lib\\site-packages\\xmldiff\\main.py:27\u001b[0m, in \u001b[0;36mdiff_trees\u001b[1;34m(left, right, diff_options, formatter)\u001b[0m\n\u001b[0;32m     24\u001b[0m diffs \u001b[38;5;241m=\u001b[39m differ\u001b[38;5;241m.\u001b[39mdiff(left, right)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m formatter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdiffs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatter\u001b[38;5;241m.\u001b[39mformat(diffs, left)\n",
      "File \u001b[1;32mc:\\Interview_Preparation\\.venv\\lib\\site-packages\\xmldiff\\diff.py:427\u001b[0m, in \u001b[0;36mDiffer.diff\u001b[1;34m(self, left, right)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdiff\u001b[39m(\u001b[38;5;28mself\u001b[39m, left\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, right\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;66;03m# Make sure the matching is done first, diff() needs the l2r/r2l maps.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_matches:\n\u001b[1;32m--> 427\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;66;03m# First, deal with namespaces:\u001b[39;00m\n\u001b[0;32m    430\u001b[0m     rnsmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright\u001b[38;5;241m.\u001b[39mnsmap\n",
      "File \u001b[1;32mc:\\Interview_Preparation\\.venv\\lib\\site-packages\\xmldiff\\diff.py:93\u001b[0m, in \u001b[0;36mDiffer.match\u001b[1;34m(self, left, right)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatch\u001b[39m(\u001b[38;5;28mself\u001b[39m, left\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, right\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# This is not a generator, because the diff() functions needs\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# _l2rmap and _r2lmap, so if match() was a generator, then\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;66;03m# actually do not want a diff, but only a list of matches.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;66;03m# It also makes testing the match function easier.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_trees\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_matches \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;66;03m# We already matched these sequences, use the cache\u001b[39;00m\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_matches\n",
      "File \u001b[1;32mc:\\Interview_Preparation\\.venv\\lib\\site-packages\\xmldiff\\diff.py:68\u001b[0m, in \u001b[0;36mDiffer.set_trees\u001b[1;34m(self, left, right)\u001b[0m\n\u001b[0;32m     65\u001b[0m     right \u001b[38;5;241m=\u001b[39m right\u001b[38;5;241m.\u001b[39mgetroot()\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (etree\u001b[38;5;241m.\u001b[39miselement(left) \u001b[38;5;129;01mand\u001b[39;00m etree\u001b[38;5;241m.\u001b[39miselement(right)):\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameters must be \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlxml Elements.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Left gets modified as a part of the diff, deepcopy it first.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m deepcopy(left)\n",
      "\u001b[1;31mTypeError\u001b[0m: The 'left' and 'right' parameters must be lxml Elements."
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    validator = FormatValidator()\n",
    "\n",
    "    # HTML example\n",
    "    # original_html = \"<html><body><h1>Hello</h1><p class='test'>World</p></body></html>\"\n",
    "    # reconstructed_html = \"<html><body><h1>Bonjour</h1><p>Monde</p></body></html>\"\n",
    "    # print(\"HTML Validation:\", validator.validate(original_html, reconstructed_html, 'html'))\n",
    "    # print(\"Feedback:\", validator.get_feedback())\n",
    "\n",
    "    # JSON example\n",
    "    # original_json = '{\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}'\n",
    "    # reconstructed_json = '{\"name\": \"Jean\", \"age\": \"30\", \"town\": \"Paris\"}'\n",
    "    # print(\"\\nJSON Validation:\", validator.validate(original_json, reconstructed_json, 'json'))\n",
    "    # print(\"Feedback:\", validator.get_feedback())\n",
    "\n",
    "    # XML example\n",
    "    original_xml = '<root><person><name>John</name><age>30</age></person></root>'\n",
    "    reconstructed_xml = '<root><person><name>Jean</name><age>30</age><city>Paris</city></person></root>'\n",
    "    print(\"\\nXML Validation:\", validator.validate(original_xml, reconstructed_xml, 'xml'))\n",
    "    print(\"Feedback:\", validator.get_feedback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xmldiff\n",
      "  Downloading xmldiff-2.7.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: setuptools in c:\\interview_preparation\\.venv\\lib\\site-packages (from xmldiff) (65.5.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\interview_preparation\\.venv\\lib\\site-packages (from xmldiff) (5.3.0)\n",
      "Downloading xmldiff-2.7.0-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: xmldiff\n",
      "Successfully installed xmldiff-2.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xmldiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonschema\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\interview_preparation\\.venv\\lib\\site-packages (from jsonschema) (24.1.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema)\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema)\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema)\n",
      "  Downloading rpds_py-0.20.0-cp310-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.20.0-cp310-none-win_amd64.whl (213 kB)\n",
      "Installing collected packages: rpds-py, referencing, jsonschema-specifications, jsonschema\n",
      "Successfully installed jsonschema-4.23.0 jsonschema-specifications-2024.10.1 referencing-0.35.1 rpds-py-0.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install jsonschema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html5lib\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: six>=1.9 in c:\\interview_preparation\\.venv\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Collecting webencodings (from html5lib)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, html5lib\n",
      "Successfully installed html5lib-1.1 webencodings-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\interview_preparation\\.venv\\lib\\site-packages (5.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html5lib in c:\\interview_preparation\\.venv\\lib\\site-packages (1.1)\n",
      "Requirement already satisfied: lxml in c:\\interview_preparation\\.venv\\lib\\site-packages (5.3.0)\n",
      "Requirement already satisfied: six>=1.9 in c:\\interview_preparation\\.venv\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\interview_preparation\\.venv\\lib\\site-packages (from html5lib) (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install html5lib lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: format_validator.py\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import xmldiff.main\n",
    "import jsonschema\n",
    "\n",
    "class FormatValidator:\n",
    "    def __init__(self):\n",
    "        self.errors = []\n",
    "        self.suggestions = []\n",
    "\n",
    "    def validate(self, original_content, reconstructed_content, format_type):\n",
    "        self.errors = []\n",
    "        self.suggestions = []\n",
    "        \n",
    "        if format_type == 'html':\n",
    "            return self._validate_html(original_content, reconstructed_content)\n",
    "        elif format_type == 'json':\n",
    "            return self._validate_json(original_content, reconstructed_content)\n",
    "        elif format_type == 'xml':\n",
    "            return self._validate_xml(original_content, reconstructed_content)\n",
    "        else:\n",
    "            self.errors.append(f\"Unsupported format: {format_type}\")\n",
    "            return False\n",
    "\n",
    "    def _validate_html(self, original_html, reconstructed_html):\n",
    "        parsers = ['html5lib', 'lxml', 'html.parser']\n",
    "        original_soup = None\n",
    "        reconstructed_soup = None\n",
    "\n",
    "        for parser in parsers:\n",
    "            try:\n",
    "                original_soup = BeautifulSoup(original_html, parser)\n",
    "                reconstructed_soup = BeautifulSoup(reconstructed_html, parser)\n",
    "                break\n",
    "            except ImportError:\n",
    "                continue\n",
    "\n",
    "        if original_soup is None or reconstructed_soup is None:\n",
    "            self.errors.append(\"Failed to parse HTML. Please install 'html5lib' or 'lxml' for better HTML parsing.\")\n",
    "            return False\n",
    "\n",
    "        # Check 1: Basic HTML parsing\n",
    "        if original_soup.find() is None:\n",
    "            self.errors.append(\"Original HTML is not parseable\")\n",
    "            return False\n",
    "        if reconstructed_soup.find() is None:\n",
    "            self.errors.append(\"Reconstructed HTML is not parseable\")\n",
    "            self.suggestions.append(\"Ensure the reconstructed HTML has a valid structure with proper opening and closing tags.\")\n",
    "            return False\n",
    "\n",
    "        # Check 2: Compare tag counts\n",
    "        original_tags = Counter(tag.name for tag in original_soup.find_all())\n",
    "        reconstructed_tags = Counter(tag.name for tag in reconstructed_soup.find_all())\n",
    "        if original_tags != reconstructed_tags:\n",
    "            self.errors.append(\"Tag count mismatch\")\n",
    "            self.suggestions.append(f\"Adjust the number of HTML tags to match the original. Original counts: {dict(original_tags)}, Reconstructed counts: {dict(reconstructed_tags)}\")\n",
    "\n",
    "        # Check 3: Structure comparison\n",
    "        if not self._compare_html_structure(original_soup, reconstructed_soup):\n",
    "            self.errors.append(\"Overall HTML structure mismatch\")\n",
    "            self.suggestions.append(\"Ensure the hierarchical structure of HTML elements matches the original.\")\n",
    "\n",
    "        # Check 4: Attribute preservation\n",
    "        if not self._compare_html_attributes(original_soup, reconstructed_soup):\n",
    "            self.errors.append(\"HTML attribute mismatch\")\n",
    "            self.suggestions.append(\"Preserve all original HTML attributes, including their values.\")\n",
    "\n",
    "        # Check 5: Content length comparison\n",
    "        original_content_length = len(original_soup.get_text())\n",
    "        reconstructed_content_length = len(reconstructed_soup.get_text())\n",
    "        if abs(original_content_length - reconstructed_content_length) > original_content_length * 0.2:  # 20% tolerance\n",
    "            self.errors.append(\"Significant content length difference\")\n",
    "            self.suggestions.append(f\"Adjust the content length to be within 20% of the original. Original length: {original_content_length}, Reconstructed length: {reconstructed_content_length}\")\n",
    "\n",
    "        return len(self.errors) == 0\n",
    "\n",
    "    def _validate_json(self, original_json, reconstructed_json):\n",
    "        try:\n",
    "            original_dict = json.loads(original_json)\n",
    "            reconstructed_dict = json.loads(reconstructed_json)\n",
    "        except json.JSONDecodeError as e:\n",
    "            self.errors.append(f\"Invalid JSON format: {str(e)}\")\n",
    "            self.suggestions.append(\"Ensure the JSON is properly formatted with correct syntax.\")\n",
    "            return False\n",
    "\n",
    "        # Check 1: Schema validation\n",
    "        schema = self._generate_json_schema(original_dict)\n",
    "        try:\n",
    "            jsonschema.validate(instance=reconstructed_dict, schema=schema)\n",
    "        except jsonschema.exceptions.ValidationError as ve:\n",
    "            self.errors.append(f\"JSON schema validation failed: {ve}\")\n",
    "            self.suggestions.append(\"Adjust the JSON structure and types to match the original schema.\")\n",
    "            return False\n",
    "\n",
    "        # Check 2: Structure comparison\n",
    "        if not self._compare_json_structure(original_dict, reconstructed_dict):\n",
    "            self.errors.append(\"JSON structure mismatch\")\n",
    "            self.suggestions.append(\"Ensure all keys and nested structures in the JSON match the original.\")\n",
    "\n",
    "        # Check 3: Value type preservation\n",
    "        type_mismatches = self._check_json_value_types(original_dict, reconstructed_dict)\n",
    "        if type_mismatches:\n",
    "            self.errors.append(\"JSON value type mismatch\")\n",
    "            self.suggestions.extend(type_mismatches)\n",
    "\n",
    "        return len(self.errors) == 0\n",
    "\n",
    "    def _validate_xml(self, original_xml, reconstructed_xml):\n",
    "        try:\n",
    "            original_root = etree.fromstring(original_xml.encode())\n",
    "            reconstructed_root = etree.fromstring(reconstructed_xml.encode())\n",
    "        except etree.XMLSyntaxError as e:\n",
    "            self.errors.append(f\"Invalid XML format: {str(e)}\")\n",
    "            self.suggestions.append(\"Ensure the XML is well-formed with proper opening and closing tags.\")\n",
    "            return False\n",
    "\n",
    "        # Check 1: Structure comparison\n",
    "        try:\n",
    "            diff = xmldiff.main.diff_trees(original_root, reconstructed_root)\n",
    "            if diff:\n",
    "                self.errors.append(\"XML structure mismatch\")\n",
    "                self.suggestions.append(\"Ensure the XML element structure and hierarchy match the original.\")\n",
    "        except Exception as e:\n",
    "            self.errors.append(f\"Error in XML comparison: {str(e)}\")\n",
    "            self.suggestions.append(\"There was an issue comparing the XML structures. Please check the XML content.\")\n",
    "\n",
    "        # Check 2: Attribute preservation\n",
    "        if not self._compare_xml_attributes(original_root, reconstructed_root):\n",
    "            self.errors.append(\"XML attributes mismatch\")\n",
    "            self.suggestions.append(\"Preserve all original XML attributes, including their values.\")\n",
    "\n",
    "        # Check 3: Element count\n",
    "        original_count = self._count_xml_elements(original_root)\n",
    "        reconstructed_count = self._count_xml_elements(reconstructed_root)\n",
    "        if original_count != reconstructed_count:\n",
    "            self.errors.append(\"XML element count mismatch\")\n",
    "            self.suggestions.append(f\"Adjust the number of XML elements to match the original. Original count: {original_count}, Reconstructed count: {reconstructed_count}\")\n",
    "\n",
    "        return len(self.errors) == 0\n",
    "\n",
    "    def _compare_html_structure(self, soup1, soup2):\n",
    "        def get_structure(soup):\n",
    "            return ''.join(element.name for element in soup.descendants if element.name)\n",
    "        return get_structure(soup1) == get_structure(soup2)\n",
    "\n",
    "    def _compare_html_attributes(self, soup1, soup2):\n",
    "        elements1 = soup1.find_all()\n",
    "        elements2 = soup2.find_all()\n",
    "        if len(elements1) != len(elements2):\n",
    "            return False\n",
    "        return all(e1.attrs == e2.attrs for e1, e2 in zip(elements1, elements2))\n",
    "\n",
    "    def _generate_json_schema(self, json_dict):\n",
    "        def get_type(value):\n",
    "            if isinstance(value, str):\n",
    "                return \"string\"\n",
    "            elif isinstance(value, bool):\n",
    "                return \"boolean\"\n",
    "            elif isinstance(value, int):\n",
    "                return \"integer\"\n",
    "            elif isinstance(value, float):\n",
    "                return \"number\"\n",
    "            elif isinstance(value, list):\n",
    "                return \"array\"\n",
    "            elif isinstance(value, dict):\n",
    "                return \"object\"\n",
    "            else:\n",
    "                return \"null\"\n",
    "\n",
    "        schema = {\"type\": \"object\", \"properties\": {}}\n",
    "        for key, value in json_dict.items():\n",
    "            if isinstance(value, dict):\n",
    "                schema[\"properties\"][key] = self._generate_json_schema(value)\n",
    "            elif isinstance(value, list):\n",
    "                schema[\"properties\"][key] = {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": self._generate_json_schema(value[0]) if value else {}\n",
    "                }\n",
    "            else:\n",
    "                schema[\"properties\"][key] = {\"type\": get_type(value)}\n",
    "        return schema\n",
    "\n",
    "    def _compare_json_structure(self, dict1, dict2):\n",
    "        if not isinstance(dict1, type(dict2)):\n",
    "            return False\n",
    "        if isinstance(dict1, dict):\n",
    "            return set(dict1.keys()) == set(dict2.keys()) and all(self._compare_json_structure(dict1[k], dict2[k]) for k in dict1)\n",
    "        if isinstance(dict1, list):\n",
    "            return len(dict1) == len(dict2) and all(self._compare_json_structure(v1, v2) for v1, v2 in zip(dict1, dict2))\n",
    "        return True\n",
    "\n",
    "    def _check_json_value_types(self, dict1, dict2, path=\"\"):\n",
    "        mismatches = []\n",
    "        if isinstance(dict1, dict):\n",
    "            for k in dict1:\n",
    "                new_path = f\"{path}.{k}\" if path else k\n",
    "                if k in dict2:\n",
    "                    mismatches.extend(self._check_json_value_types(dict1[k], dict2[k], new_path))\n",
    "                else:\n",
    "                    mismatches.append(f\"Missing key at {new_path}\")\n",
    "        elif isinstance(dict1, list):\n",
    "            if len(dict1) != len(dict2):\n",
    "                mismatches.append(f\"Array length mismatch at {path}\")\n",
    "            else:\n",
    "                for i, (v1, v2) in enumerate(zip(dict1, dict2)):\n",
    "                    mismatches.extend(self._check_json_value_types(v1, v2, f\"{path}[{i}]\"))\n",
    "        elif type(dict1) != type(dict2):\n",
    "            mismatches.append(f\"Type mismatch at {path}: expected {type(dict1).__name__}, got {type(dict2).__name__}\")\n",
    "        return mismatches\n",
    "\n",
    "    def _compare_xml_attributes(self, elem1, elem2):\n",
    "        if elem1.tag != elem2.tag:\n",
    "            return False\n",
    "        if elem1.attrib != elem2.attrib:\n",
    "            return False\n",
    "        if len(elem1) != len(elem2):\n",
    "            return False\n",
    "        return all(self._compare_xml_attributes(c1, c2) for c1, c2 in zip(elem1, elem2))\n",
    "\n",
    "    def _count_xml_elements(self, elem):\n",
    "        return 1 + sum(self._count_xml_elements(child) for child in elem)\n",
    "\n",
    "    def get_feedback(self):\n",
    "        return {\n",
    "            \"errors\": self.errors,\n",
    "            \"suggestions\": self.suggestions\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: format_validator.py\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import xmldiff.main\n",
    "import jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatValidator:\n",
    "    def __init__(self):\n",
    "        self.errors = []\n",
    "        self.suggestions = []\n",
    "\n",
    "    def validate(self, original_content, reconstructed_content, format_type):\n",
    "        self.errors = []\n",
    "        self.suggestions = []\n",
    "        \n",
    "        if format_type == 'html':\n",
    "            return self._validate_html(original_content, reconstructed_content)\n",
    "        elif format_type == 'json':\n",
    "            return self._validate_json(original_content, reconstructed_content)\n",
    "        elif format_type == 'xml':\n",
    "            return self._validate_xml(original_content, reconstructed_content)\n",
    "        else:\n",
    "            self.errors.append(f\"Unsupported format: {format_type}\")\n",
    "            return False\n",
    "\n",
    "    def _validate_html(self, original_html, reconstructed_html):\n",
    "        parsers = ['html5lib', 'lxml', 'html.parser']\n",
    "        original_soup = None\n",
    "        reconstructed_soup = None\n",
    "\n",
    "        for parser in parsers:\n",
    "            try:\n",
    "                original_soup = BeautifulSoup(original_html, parser)\n",
    "                reconstructed_soup = BeautifulSoup(reconstructed_html, parser)\n",
    "                break\n",
    "            except ImportError:\n",
    "                continue\n",
    "\n",
    "        if original_soup is None or reconstructed_soup is None:\n",
    "            self.errors.append(\"Failed to parse HTML. Please install 'html5lib' or 'lxml' for better HTML parsing.\")\n",
    "            return False\n",
    "\n",
    "        # Check 1: Basic HTML parsing\n",
    "        if original_soup.find() is None:\n",
    "            self.errors.append(\"Original HTML is not parseable\")\n",
    "            return False\n",
    "        if reconstructed_soup.find() is None:\n",
    "            self.errors.append(\"Reconstructed HTML is not parseable\")\n",
    "            self.suggestions.append(\"Ensure the reconstructed HTML has a valid structure with proper opening and closing tags.\")\n",
    "            return False\n",
    "\n",
    "        # Check 2: Compare tag counts\n",
    "        original_tags = Counter(tag.name for tag in original_soup.find_all())\n",
    "        reconstructed_tags = Counter(tag.name for tag in reconstructed_soup.find_all())\n",
    "        if original_tags != reconstructed_tags:\n",
    "            self.errors.append(\"Tag count mismatch\")\n",
    "            self.suggestions.append(f\"Adjust the number of HTML tags to match the original. Original counts: {dict(original_tags)}, Reconstructed counts: {dict(reconstructed_tags)}\")\n",
    "\n",
    "        # Check 3: Structure comparison\n",
    "        if not self._compare_html_structure(original_soup, reconstructed_soup):\n",
    "            self.errors.append(\"Overall HTML structure mismatch\")\n",
    "            self.suggestions.append(\"Ensure the hierarchical structure of HTML elements matches the original.\")\n",
    "\n",
    "        # Check 4: Attribute preservation\n",
    "        if not self._compare_html_attributes(original_soup, reconstructed_soup):\n",
    "            self.errors.append(\"HTML attribute mismatch\")\n",
    "            self.suggestions.append(\"Preserve all original HTML attributes, including their values.\")\n",
    "\n",
    "        # Check 5: Content length comparison\n",
    "        original_content_length = len(original_soup.get_text())\n",
    "        reconstructed_content_length = len(reconstructed_soup.get_text())\n",
    "        if abs(original_content_length - reconstructed_content_length) > original_content_length * 0.2:  # 20% tolerance\n",
    "            self.errors.append(\"Significant content length difference\")\n",
    "            self.suggestions.append(f\"Adjust the content length to be within 20% of the original. Original length: {original_content_length}, Reconstructed length: {reconstructed_content_length}\")\n",
    "\n",
    "        return len(self.errors) == 0\n",
    "\n",
    "    def _validate_json(self, original_json, reconstructed_json):\n",
    "        try:\n",
    "            original_dict = json.loads(original_json)\n",
    "            reconstructed_dict = json.loads(reconstructed_json)\n",
    "        except json.JSONDecodeError as e:\n",
    "            self.errors.append(f\"Invalid JSON format: {str(e)}\")\n",
    "            self.suggestions.append(\"Ensure the JSON is properly formatted with correct syntax.\")\n",
    "            return False\n",
    "\n",
    "        # Check 1: Schema validation\n",
    "        schema = self._generate_json_schema(original_dict)\n",
    "        try:\n",
    "            jsonschema.validate(instance=reconstructed_dict, schema=schema)\n",
    "        except jsonschema.exceptions.ValidationError as ve:\n",
    "            self.errors.append(f\"JSON schema validation failed: {ve}\")\n",
    "            self.suggestions.append(\"Adjust the JSON structure and types to match the original schema.\")\n",
    "            return False\n",
    "\n",
    "        # Check 2: Structure comparison\n",
    "        if not self._compare_json_structure(original_dict, reconstructed_dict):\n",
    "            self.errors.append(\"JSON structure mismatch\")\n",
    "            self.suggestions.append(\"Ensure all keys and nested structures in the JSON match the original.\")\n",
    "\n",
    "        # Check 3: Value type preservation\n",
    "        type_mismatches = self._check_json_value_types(original_dict, reconstructed_dict)\n",
    "        if type_mismatches:\n",
    "            self.errors.append(\"JSON value type mismatch\")\n",
    "            self.suggestions.extend(type_mismatches)\n",
    "\n",
    "        return len(self.errors) == 0\n",
    "\n",
    "    def _validate_xml(self, original_xml, reconstructed_xml):\n",
    "        try:\n",
    "            original_root = etree.fromstring(original_xml.encode())\n",
    "            reconstructed_root = etree.fromstring(reconstructed_xml.encode())\n",
    "        except etree.XMLSyntaxError as e:\n",
    "            self.errors.append(f\"Invalid XML format: {str(e)}\")\n",
    "            self.suggestions.append(\"Ensure the XML is well-formed with proper opening and closing tags.\")\n",
    "            return False\n",
    "\n",
    "        # Check 1: Structure comparison\n",
    "        try:\n",
    "            diff = xmldiff.main.diff_trees(original_root, reconstructed_root)\n",
    "            if diff:\n",
    "                self.errors.append(\"XML structure mismatch\")\n",
    "                self.suggestions.append(\"Ensure the XML element structure and hierarchy match the original.\")\n",
    "        except Exception as e:\n",
    "            self.errors.append(f\"Error in XML comparison: {str(e)}\")\n",
    "            self.suggestions.append(\"There was an issue comparing the XML structures. Please check the XML content.\")\n",
    "\n",
    "        # Check 2: Attribute preservation\n",
    "        if not self._compare_xml_attributes(original_root, reconstructed_root):\n",
    "            self.errors.append(\"XML attributes mismatch\")\n",
    "            self.suggestions.append(\"Preserve all original XML attributes, including their values.\")\n",
    "\n",
    "        # Check 3: Element count\n",
    "        original_count = self._count_xml_elements(original_root)\n",
    "        reconstructed_count = self._count_xml_elements(reconstructed_root)\n",
    "        if original_count != reconstructed_count:\n",
    "            self.errors.append(\"XML element count mismatch\")\n",
    "            self.suggestions.append(f\"Adjust the number of XML elements to match the original. Original count: {original_count}, Reconstructed count: {reconstructed_count}\")\n",
    "\n",
    "        return len(self.errors) == 0\n",
    "\n",
    "    def _compare_html_structure(self, soup1, soup2):\n",
    "        def get_structure(soup):\n",
    "            return ''.join(element.name for element in soup.descendants if element.name)\n",
    "        return get_structure(soup1) == get_structure(soup2)\n",
    "\n",
    "    def _compare_html_attributes(self, soup1, soup2):\n",
    "        elements1 = soup1.find_all()\n",
    "        elements2 = soup2.find_all()\n",
    "        if len(elements1) != len(elements2):\n",
    "            return False\n",
    "        return all(e1.attrs == e2.attrs for e1, e2 in zip(elements1, elements2))\n",
    "\n",
    "    def _generate_json_schema(self, json_dict):\n",
    "        def get_type(value):\n",
    "            if isinstance(value, str):\n",
    "                return \"string\"\n",
    "            elif isinstance(value, bool):\n",
    "                return \"boolean\"\n",
    "            elif isinstance(value, int):\n",
    "                return \"integer\"\n",
    "            elif isinstance(value, float):\n",
    "                return \"number\"\n",
    "            elif isinstance(value, list):\n",
    "                return \"array\"\n",
    "            elif isinstance(value, dict):\n",
    "                return \"object\"\n",
    "            else:\n",
    "                return \"null\"\n",
    "\n",
    "        schema = {\"type\": \"object\", \"properties\": {}}\n",
    "        for key, value in json_dict.items():\n",
    "            if isinstance(value, dict):\n",
    "                schema[\"properties\"][key] = self._generate_json_schema(value)\n",
    "            elif isinstance(value, list):\n",
    "                schema[\"properties\"][key] = {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": self._generate_json_schema(value[0]) if value else {}\n",
    "                }\n",
    "            else:\n",
    "                schema[\"properties\"][key] = {\"type\": get_type(value)}\n",
    "        return schema\n",
    "\n",
    "    def _compare_json_structure(self, dict1, dict2):\n",
    "        if not isinstance(dict1, type(dict2)):\n",
    "            return False\n",
    "        if isinstance(dict1, dict):\n",
    "            return set(dict1.keys()) == set(dict2.keys()) and all(self._compare_json_structure(dict1[k], dict2[k]) for k in dict1)\n",
    "        if isinstance(dict1, list):\n",
    "            return len(dict1) == len(dict2) and all(self._compare_json_structure(v1, v2) for v1, v2 in zip(dict1, dict2))\n",
    "        return True\n",
    "\n",
    "    def _check_json_value_types(self, dict1, dict2, path=\"\"):\n",
    "        mismatches = []\n",
    "        if isinstance(dict1, dict):\n",
    "            for k in dict1:\n",
    "                new_path = f\"{path}.{k}\" if path else k\n",
    "                if k in dict2:\n",
    "                    mismatches.extend(self._check_json_value_types(dict1[k], dict2[k], new_path))\n",
    "                else:\n",
    "                    mismatches.append(f\"Missing key at {new_path}\")\n",
    "        elif isinstance(dict1, list):\n",
    "            if len(dict1) != len(dict2):\n",
    "                mismatches.append(f\"Array length mismatch at {path}\")\n",
    "            else:\n",
    "                for i, (v1, v2) in enumerate(zip(dict1, dict2)):\n",
    "                    mismatches.extend(self._check_json_value_types(v1, v2, f\"{path}[{i}]\"))\n",
    "        elif type(dict1) != type(dict2):\n",
    "            mismatches.append(f\"Type mismatch at {path}: expected {type(dict1).__name__}, got {type(dict2).__name__}\")\n",
    "        return mismatches\n",
    "\n",
    "    def _compare_xml_attributes(self, elem1, elem2):\n",
    "        if elem1.tag != elem2.tag:\n",
    "            return False\n",
    "        if elem1.attrib != elem2.attrib:\n",
    "            return False\n",
    "        if len(elem1) != len(elem2):\n",
    "            return False\n",
    "        return all(self._compare_xml_attributes(c1, c2) for c1, c2 in zip(elem1, elem2))\n",
    "\n",
    "    def _count_xml_elements(self, elem):\n",
    "        return 1 + sum(self._count_xml_elements(child) for child in elem)\n",
    "\n",
    "    def get_feedback(self):\n",
    "        return {\n",
    "            \"errors\": self.errors,\n",
    "            \"suggestions\": self.suggestions\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XML Validation: False\n",
      "Feedback: {'errors': ['XML structure mismatch'], 'suggestions': ['Ensure the XML element structure and hierarchy match the original.']}\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    validator = FormatValidator()\n",
    "\n",
    "    # HTML example\n",
    "    original_html = \"<html><body><h1>Hello</h1><p class='test'>World</p></body></html>\"\n",
    "    reconstructed_html = \"<html><body><h1>Bonjour</h1><p>Monde</p></body></html>\"\n",
    "    print(\"HTML Validation:\", validator.validate(original_html, reconstructed_html, 'html'))\n",
    "    print(\"Feedback:\", validator.get_feedback())\n",
    "\n",
    "    # JSON example\n",
    "    original_json = '{\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}'\n",
    "    reconstructed_json = '{\"name\": \"Jean\", \"age\": 30, \"town\": \"Paris\"}'\n",
    "    print(\"\\nJSON Validation:\", validator.validate(original_json, reconstructed_json, 'json'))\n",
    "    print(\"Feedback:\", validator.get_feedback())\n",
    "\n",
    "    # XML example\n",
    "    original_xml = '<root><person><name>John</name><age>30</age></person></root>'\n",
    "    reconstructed_xml = '<root><person><name>John</name><age>30</age></person></root>'\n",
    "    print(\"\\nXML Validation:\", validator.validate(original_xml, reconstructed_xml, 'xml'))\n",
    "    print(\"Feedback:\", validator.get_feedback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import xmldiff.main\n",
    "import jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComprehensiveStructureValidator:\n",
    "    def __init__(self):\n",
    "        self.errors = []\n",
    "        self.suggestions = []\n",
    "\n",
    "    def validate(self, original_content, reconstructed_content, format_type):\n",
    "        self.errors = []\n",
    "        self.suggestions = []\n",
    "        \n",
    "        if format_type == 'html':\n",
    "            return self._validate_html(original_content, reconstructed_content)\n",
    "        elif format_type == 'json':\n",
    "            return self._validate_json(original_content, reconstructed_content)\n",
    "        elif format_type == 'xml':\n",
    "            return self._validate_xml(original_content, reconstructed_content)\n",
    "        else:\n",
    "            self.errors.append(f\"Unsupported format: {format_type}\")\n",
    "            return False\n",
    "\n",
    "    def _validate_html(self, original_html, reconstructed_html):\n",
    "        parsers = ['html5lib', 'lxml', 'html.parser']\n",
    "        original_soup = None\n",
    "        reconstructed_soup = None\n",
    "\n",
    "        for parser in parsers:\n",
    "            try:\n",
    "                original_soup = BeautifulSoup(original_html, parser)\n",
    "                reconstructed_soup = BeautifulSoup(reconstructed_html, parser)\n",
    "                break\n",
    "            except ImportError:\n",
    "                continue\n",
    "\n",
    "        if original_soup is None or reconstructed_soup is None:\n",
    "            self.errors.append(\"Failed to parse HTML. Please install 'html5lib' or 'lxml' for better HTML parsing.\")\n",
    "            return False\n",
    "\n",
    "        # Check 1: Basic HTML parsing\n",
    "        if original_soup.find() is None or reconstructed_soup.find() is None:\n",
    "            self.errors.append(\"HTML is not parseable\")\n",
    "            self.suggestions.append(\"Ensure the HTML has a valid structure with proper opening and closing tags.\")\n",
    "            return False\n",
    "\n",
    "        # Check 2: Compare tag counts\n",
    "        original_tags = Counter(tag.name for tag in original_soup.find_all())\n",
    "        reconstructed_tags = Counter(tag.name for tag in reconstructed_soup.find_all())\n",
    "        if original_tags != reconstructed_tags:\n",
    "            self.errors.append(\"Tag count mismatch\")\n",
    "            self.suggestions.append(f\"Adjust the number of HTML tags to match the original. Original counts: {dict(original_tags)}, Reconstructed counts: {dict(reconstructed_tags)}\")\n",
    "\n",
    "        # Check 3: Structure comparison\n",
    "        if not self._compare_html_structure(original_soup, reconstructed_soup):\n",
    "            self.errors.append(\"Overall HTML structure mismatch\")\n",
    "            self.suggestions.append(\"Ensure the hierarchical structure of HTML elements matches the original.\")\n",
    "\n",
    "        # Check 4: Attribute preservation\n",
    "        if not self._compare_html_attributes(original_soup, reconstructed_soup):\n",
    "            self.errors.append(\"HTML attribute mismatch\")\n",
    "            self.suggestions.append(\"Preserve all original HTML attributes, including their values.\")\n",
    "\n",
    "        # Check 5: Class and ID preservation\n",
    "        if not self._compare_html_classes_and_ids(original_soup, reconstructed_soup):\n",
    "            self.errors.append(\"Mismatch in HTML classes or IDs\")\n",
    "            self.suggestions.append(\"Ensure all class names and IDs are preserved in the reconstructed HTML.\")\n",
    "\n",
    "        # Check 6: Form structure preservation\n",
    "        if not self._compare_html_forms(original_soup, reconstructed_soup):\n",
    "            self.errors.append(\"Mismatch in HTML form structures\")\n",
    "            self.suggestions.append(\"Ensure all form elements and their attributes are preserved.\")\n",
    "\n",
    "        return len(self.errors) == 0\n",
    "\n",
    "    def _validate_json(self, original_json, reconstructed_json):\n",
    "        try:\n",
    "            original_dict = json.loads(original_json)\n",
    "            reconstructed_dict = json.loads(reconstructed_json)\n",
    "        except json.JSONDecodeError as e:\n",
    "            self.errors.append(f\"Invalid JSON format: {str(e)}\")\n",
    "            self.suggestions.append(\"Ensure the JSON is properly formatted with correct syntax.\")\n",
    "            return False\n",
    "\n",
    "        # Check 1: Schema validation\n",
    "        schema = self._generate_json_schema(original_dict)\n",
    "        try:\n",
    "            jsonschema.validate(instance=reconstructed_dict, schema=schema)\n",
    "        except jsonschema.exceptions.ValidationError as ve:\n",
    "            self.errors.append(f\"JSON schema validation failed: {ve}\")\n",
    "            self.suggestions.append(\"Adjust the JSON structure to match the original schema.\")\n",
    "            return False\n",
    "\n",
    "        # Check 2: Structure comparison\n",
    "        if not self._compare_json_structure(original_dict, reconstructed_dict):\n",
    "            self.errors.append(\"JSON structure mismatch\")\n",
    "            self.suggestions.append(\"Ensure all keys and nested structures in the JSON match the original.\")\n",
    "\n",
    "        # Check 3: Array length preservation\n",
    "        if not self._compare_json_array_lengths(original_dict, reconstructed_dict):\n",
    "            self.errors.append(\"JSON array length mismatch\")\n",
    "            self.suggestions.append(\"Ensure all arrays in the JSON have the same length as in the original.\")\n",
    "\n",
    "        return len(self.errors) == 0\n",
    "\n",
    "    def _validate_xml(self, original_xml, reconstructed_xml):\n",
    "        try:\n",
    "            original_root = etree.fromstring(original_xml.encode())\n",
    "            reconstructed_root = etree.fromstring(reconstructed_xml.encode())\n",
    "        except etree.XMLSyntaxError as e:\n",
    "            self.errors.append(f\"Invalid XML format: {str(e)}\")\n",
    "            self.suggestions.append(\"Ensure the XML is well-formed with proper opening and closing tags.\")\n",
    "            return False\n",
    "\n",
    "        # Check 1: Structure comparison\n",
    "        try:\n",
    "            diff = xmldiff.main.diff_trees(original_root, reconstructed_root)\n",
    "            if diff:\n",
    "                self.errors.append(\"XML structure mismatch\")\n",
    "                self.suggestions.append(\"Ensure the XML element structure and hierarchy match the original.\")\n",
    "        except Exception as e:\n",
    "            self.errors.append(f\"Error in XML comparison: {str(e)}\")\n",
    "            self.suggestions.append(\"There was an issue comparing the XML structures. Please check the XML content.\")\n",
    "\n",
    "        # Check 2: Attribute preservation\n",
    "        if not self._compare_xml_attributes(original_root, reconstructed_root):\n",
    "            self.errors.append(\"XML attributes mismatch\")\n",
    "            self.suggestions.append(\"Preserve all original XML attributes, including their values.\")\n",
    "\n",
    "        # Check 3: Element count\n",
    "        original_count = self._count_xml_elements(original_root)\n",
    "        reconstructed_count = self._count_xml_elements(reconstructed_root)\n",
    "        if original_count != reconstructed_count:\n",
    "            self.errors.append(\"XML element count mismatch\")\n",
    "            self.suggestions.append(f\"Adjust the number of XML elements to match the original. Original count: {original_count}, Reconstructed count: {reconstructed_count}\")\n",
    "\n",
    "        # Check 4: Namespace preservation\n",
    "        if not self._compare_xml_namespaces(original_root, reconstructed_root):\n",
    "            self.errors.append(\"XML namespace mismatch\")\n",
    "            self.suggestions.append(\"Ensure all XML namespaces are preserved in the reconstructed XML.\")\n",
    "\n",
    "        return len(self.errors) == 0\n",
    "\n",
    "    def _compare_html_structure(self, soup1, soup2):\n",
    "        def get_structure(soup):\n",
    "            return ''.join(element.name for element in soup.descendants if element.name)\n",
    "        return get_structure(soup1) == get_structure(soup2)\n",
    "\n",
    "    def _compare_html_attributes(self, soup1, soup2):\n",
    "        elements1 = soup1.find_all()\n",
    "        elements2 = soup2.find_all()\n",
    "        if len(elements1) != len(elements2):\n",
    "            return False\n",
    "        return all(e1.attrs == e2.attrs for e1, e2 in zip(elements1, elements2))\n",
    "\n",
    "    def _compare_html_classes_and_ids(self, soup1, soup2):\n",
    "        elements1 = soup1.find_all(class_=True) + soup1.find_all(id=True)\n",
    "        elements2 = soup2.find_all(class_=True) + soup2.find_all(id=True)\n",
    "        if len(elements1) != len(elements2):\n",
    "            return False\n",
    "        return all(e1.get('class') == e2.get('class') and e1.get('id') == e2.get('id') \n",
    "                   for e1, e2 in zip(elements1, elements2))\n",
    "\n",
    "    def _compare_html_forms(self, soup1, soup2):\n",
    "        forms1 = soup1.find_all('form')\n",
    "        forms2 = soup2.find_all('form')\n",
    "        if len(forms1) != len(forms2):\n",
    "            return False\n",
    "        for f1, f2 in zip(forms1, forms2):\n",
    "            if f1.attrs != f2.attrs:\n",
    "                return False\n",
    "            inputs1 = f1.find_all(['input', 'select', 'textarea'])\n",
    "            inputs2 = f2.find_all(['input', 'select', 'textarea'])\n",
    "            if len(inputs1) != len(inputs2):\n",
    "                return False\n",
    "            if any(i1.attrs != i2.attrs for i1, i2 in zip(inputs1, inputs2)):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def _generate_json_schema(self, json_dict):\n",
    "        schema = {\"type\": \"object\", \"properties\": {}}\n",
    "        for key, value in json_dict.items():\n",
    "            if isinstance(value, dict):\n",
    "                schema[\"properties\"][key] = self._generate_json_schema(value)\n",
    "            elif isinstance(value, list):\n",
    "                schema[\"properties\"][key] = {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": self._generate_json_schema(value[0]) if value else {}\n",
    "                }\n",
    "            else:\n",
    "                schema[\"properties\"][key] = {\"type\": \"string\"}  # Treat all non-structural elements as strings\n",
    "        return schema\n",
    "\n",
    "    def _compare_json_structure(self, dict1, dict2):\n",
    "        if not isinstance(dict1, type(dict2)):\n",
    "            return False\n",
    "        if isinstance(dict1, dict):\n",
    "            return set(dict1.keys()) == set(dict2.keys()) and all(self._compare_json_structure(dict1[k], dict2[k]) for k in dict1)\n",
    "        if isinstance(dict1, list):\n",
    "            return len(dict1) == len(dict2) and all(self._compare_json_structure(v1, v2) for v1, v2 in zip(dict1, dict2))\n",
    "        return True\n",
    "\n",
    "    def _compare_json_array_lengths(self, dict1, dict2):\n",
    "        if isinstance(dict1, dict) and isinstance(dict2, dict):\n",
    "            return all(self._compare_json_array_lengths(dict1[k], dict2[k]) for k in dict1 if k in dict2)\n",
    "        if isinstance(dict1, list) and isinstance(dict2, list):\n",
    "            return len(dict1) == len(dict2)\n",
    "        return True\n",
    "\n",
    "    def _compare_xml_attributes(self, elem1, elem2):\n",
    "        if elem1.tag != elem2.tag:\n",
    "            return False\n",
    "        if elem1.attrib != elem2.attrib:\n",
    "            return False\n",
    "        if len(elem1) != len(elem2):\n",
    "            return False\n",
    "        return all(self._compare_xml_attributes(c1, c2) for c1, c2 in zip(elem1, elem2))\n",
    "\n",
    "    def _count_xml_elements(self, elem):\n",
    "        return 1 + sum(self._count_xml_elements(child) for child in elem)\n",
    "\n",
    "    def _compare_xml_namespaces(self, elem1, elem2):\n",
    "        return elem1.nsmap == elem2.nsmap and all(self._compare_xml_namespaces(c1, c2) for c1, c2 in zip(elem1, elem2))\n",
    "\n",
    "    def get_feedback(self):\n",
    "        return {\n",
    "            \"errors\": self.errors,\n",
    "            \"suggestions\": self.suggestions\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML Validation: True\n",
      "Feedback: {'errors': [], 'suggestions': []}\n",
      "\n",
      "JSON Validation: False\n",
      "Feedback: {'errors': ['JSON structure mismatch'], 'suggestions': ['Ensure all keys and nested structures in the JSON match the original.']}\n",
      "\n",
      "XML Validation: False\n",
      "Feedback: {'errors': ['XML structure mismatch'], 'suggestions': ['Ensure the XML element structure and hierarchy match the original.']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    validator = ComprehensiveStructureValidator()\n",
    "\n",
    "    # HTML example\n",
    "    original_html = \"<html><body><h1 class='title'>Hello</h1><p id='content'>World</p></body></html>\"\n",
    "    reconstructed_html = \"<html><body><h1 class='title'>Bonjour</h1><p id='content'>Monde</p></body></html>\"\n",
    "    print(\"HTML Validation:\", validator.validate(original_html, reconstructed_html, 'html'))\n",
    "    print(\"Feedback:\", validator.get_feedback())\n",
    "\n",
    "    # JSON example\n",
    "    original_json = '{\"name\": \"John\", \"age\": 30, \"city\": {\"name\": \"New York\", \"population\": 8400000}}'\n",
    "    reconstructed_json = '{\"name\": \"Jean\", \"age\": \"35\", \"city\": {\"name\": \"Paris\", \"population\": \"2161000\"}}'\n",
    "    print(\"\\nJSON Validation:\", validator.validate(original_json, reconstructed_json, 'json'))\n",
    "    print(\"Feedback:\", validator.get_feedback())\n",
    "\n",
    "    # XML example\n",
    "    original_xml = '<root xmlns:x=\"http://example.com\"><person><name>John</name><age>30</age></person></root>'\n",
    "    reconstructed_xml = '<root xmlns:x=\"http://example.com\"><person><name>Jean</name><age>35</age></person></root>'\n",
    "    print(\"\\nXML Validation:\", validator.validate(original_xml, reconstructed_xml, 'xml'))\n",
    "    print(\"Feedback:\", validator.get_feedback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\interview_preparation\\.venv\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: lxml in c:\\interview_preparation\\.venv\\lib\\site-packages (5.3.0)\n",
      "Requirement already satisfied: html5lib in c:\\interview_preparation\\.venv\\lib\\site-packages (1.1)\n",
      "Requirement already satisfied: jsonschema in c:\\interview_preparation\\.venv\\lib\\site-packages (4.23.0)\n",
      "Collecting xmlschema\n",
      "  Downloading xmlschema-3.4.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\interview_preparation\\.venv\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in c:\\interview_preparation\\.venv\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\interview_preparation\\.venv\\lib\\site-packages (from html5lib) (0.5.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\interview_preparation\\.venv\\lib\\site-packages (from jsonschema) (24.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\interview_preparation\\.venv\\lib\\site-packages (from jsonschema) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\interview_preparation\\.venv\\lib\\site-packages (from jsonschema) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\interview_preparation\\.venv\\lib\\site-packages (from jsonschema) (0.20.0)\n",
      "Collecting elementpath<5.0.0,>=4.4.0 (from xmlschema)\n",
      "  Downloading elementpath-4.5.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Downloading xmlschema-3.4.2-py3-none-any.whl (417 kB)\n",
      "Downloading elementpath-4.5.0-py3-none-any.whl (228 kB)\n",
      "Installing collected packages: elementpath, xmlschema\n",
      "Successfully installed elementpath-4.5.0 xmlschema-3.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4 lxml html5lib jsonschema xmlschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import xmlschema\n",
    "import jsonschema\n",
    "import html5lib\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EnhancedStructureValidator:\n",
    "    def __init__(self, config=None):\n",
    "        self.config = config or {\n",
    "            'validation_level': 'normal',\n",
    "            'check_html5': True,\n",
    "            'check_accessibility': True,\n",
    "            'check_xml_schema': True,\n",
    "            'check_json_schema': True\n",
    "        }\n",
    "        self.errors = []\n",
    "        self.suggestions = []\n",
    "\n",
    "    def validate(self, original_content, reconstructed_content, format_type):\n",
    "        self.errors = []\n",
    "        self.suggestions = []\n",
    "        \n",
    "        if format_type == 'html':\n",
    "            return self._validate_html(original_content, reconstructed_content)\n",
    "        elif format_type == 'json':\n",
    "            return self._validate_json(original_content, reconstructed_content)\n",
    "        elif format_type == 'xml':\n",
    "            return self._validate_xml(original_content, reconstructed_content)\n",
    "        else:\n",
    "            self.errors.append(f\"Unsupported format: {format_type}\")\n",
    "            return False\n",
    "\n",
    "    def _validate_html(self, original_html, reconstructed_html):\n",
    "        original_soup = BeautifulSoup(original_html, 'html5lib')\n",
    "        reconstructed_soup = BeautifulSoup(reconstructed_html, 'html5lib')\n",
    "\n",
    "        # Basic structure checks\n",
    "        if not self._compare_html_structure(original_soup, reconstructed_soup):\n",
    "            self.errors.append(\"HTML structure mismatch\")\n",
    "            self.suggestions.append(\"Ensure the hierarchical structure of HTML elements matches the original.\")\n",
    "\n",
    "        # Tag count check\n",
    "        if not self._compare_html_tag_counts(original_soup, reconstructed_soup):\n",
    "            self.errors.append(\"HTML tag count mismatch\")\n",
    "            self.suggestions.append(\"Ensure the number of HTML tags matches the original.\")\n",
    "\n",
    "        # Attribute preservation check\n",
    "        if not self._compare_html_attributes(original_soup, reconstructed_soup):\n",
    "            self.errors.append(\"HTML attribute mismatch\")\n",
    "            self.suggestions.append(\"Preserve all original HTML attributes, including their values.\")\n",
    "\n",
    "        # HTML5 specific checks\n",
    "        if self.config['check_html5']:\n",
    "            self._check_html5_specific(reconstructed_soup)\n",
    "\n",
    "        # Accessibility checks\n",
    "        if self.config['check_accessibility']:\n",
    "            self._check_accessibility(reconstructed_soup)\n",
    "\n",
    "        return len(self.errors) == 0\n",
    "\n",
    "    def _validate_json(self, original_json, reconstructed_json):\n",
    "        try:\n",
    "            original_dict = json.loads(original_json)\n",
    "            reconstructed_dict = json.loads(reconstructed_json)\n",
    "        except json.JSONDecodeError as e:\n",
    "            self.errors.append(f\"Invalid JSON format: {str(e)}\")\n",
    "            self.suggestions.append(\"Ensure the JSON is properly formatted with correct syntax.\")\n",
    "            return False\n",
    "\n",
    "        # Structure comparison\n",
    "        if not self._compare_json_structure(original_dict, reconstructed_dict):\n",
    "            self.errors.append(\"JSON structure mismatch\")\n",
    "            self.suggestions.append(\"Ensure all keys and nested structures in the JSON match the original.\")\n",
    "\n",
    "        # JSON Schema validation\n",
    "        if self.config['check_json_schema']:\n",
    "            schema = self._generate_json_schema(original_dict)\n",
    "            try:\n",
    "                jsonschema.validate(instance=reconstructed_dict, schema=schema)\n",
    "            except jsonschema.exceptions.ValidationError as ve:\n",
    "                self.errors.append(f\"JSON schema validation failed: {ve}\")\n",
    "                self.suggestions.append(\"Adjust the JSON structure to match the original schema.\")\n",
    "\n",
    "        return len(self.errors) == 0\n",
    "\n",
    "    def _validate_xml(self, original_xml, reconstructed_xml):\n",
    "        try:\n",
    "            original_root = etree.fromstring(original_xml.encode())\n",
    "            reconstructed_root = etree.fromstring(reconstructed_xml.encode())\n",
    "        except etree.XMLSyntaxError as e:\n",
    "            self.errors.append(f\"Invalid XML format: {str(e)}\")\n",
    "            self.suggestions.append(\"Ensure the XML is well-formed with proper opening and closing tags.\")\n",
    "            return False\n",
    "\n",
    "        # Structure comparison\n",
    "        if not self._compare_xml_structure(original_root, reconstructed_root):\n",
    "            self.errors.append(\"XML structure mismatch\")\n",
    "            self.suggestions.append(\"Ensure the XML element structure and hierarchy match the original.\")\n",
    "\n",
    "        # Namespace check\n",
    "        if not self._compare_xml_namespaces(original_root, reconstructed_root):\n",
    "            self.errors.append(\"XML namespace mismatch\")\n",
    "            self.suggestions.append(\"Ensure all XML namespaces are preserved in the reconstructed XML.\")\n",
    "\n",
    "        # XML Schema validation\n",
    "        if self.config['check_xml_schema']:\n",
    "            schema = xmlschema.XMLSchema(original_xml)\n",
    "            if not schema.is_valid(reconstructed_xml):\n",
    "                self.errors.append(\"XML schema validation failed\")\n",
    "                self.suggestions.append(\"Ensure the reconstructed XML conforms to the schema of the original XML.\")\n",
    "\n",
    "        return len(self.errors) == 0\n",
    "\n",
    "    def _compare_html_structure(self, soup1, soup2):\n",
    "        def get_structure(soup):\n",
    "            return [\n",
    "                (elem.name, elem.get('id', ''), ' '.join(elem.get('class', [])))\n",
    "                for elem in soup.descendants if elem.name\n",
    "            ]\n",
    "        return get_structure(soup1) == get_structure(soup2)\n",
    "\n",
    "    def _compare_html_tag_counts(self, soup1, soup2):\n",
    "        count1 = Counter(tag.name for tag in soup1.find_all())\n",
    "        count2 = Counter(tag.name for tag in soup2.find_all())\n",
    "        return count1 == count2\n",
    "\n",
    "    def _compare_html_attributes(self, soup1, soup2):\n",
    "        elements1 = soup1.find_all()\n",
    "        elements2 = soup2.find_all()\n",
    "        if len(elements1) != len(elements2):\n",
    "            return False\n",
    "        return all(e1.attrs == e2.attrs for e1, e2 in zip(elements1, elements2))\n",
    "\n",
    "    def _check_html5_specific(self, soup):\n",
    "        html5_elements = {'article', 'aside', 'figcaption', 'figure', 'footer', 'header', 'main', 'mark', 'nav', 'section', 'time'}\n",
    "        for elem in soup.find_all(html5_elements):\n",
    "            if not self._is_properly_used_html5_element(elem):\n",
    "                self.errors.append(f\"Improper use of HTML5 element: {elem.name}\")\n",
    "                self.suggestions.append(f\"Ensure the {elem.name} element is used correctly according to HTML5 specifications.\")\n",
    "\n",
    "    def _is_properly_used_html5_element(self, elem):\n",
    "        # This is a simplified check. In a real-world scenario, you'd want more comprehensive rules.\n",
    "        if elem.name == 'nav' and not elem.find_all('a'):\n",
    "            return False\n",
    "        if elem.name == 'figure' and not elem.find('figcaption'):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def _check_accessibility(self, soup):\n",
    "        # Check for alt text on images\n",
    "        for img in soup.find_all('img'):\n",
    "            if not img.get('alt'):\n",
    "                self.errors.append(\"Image without alt text\")\n",
    "                self.suggestions.append(\"Add descriptive alt text to all images for accessibility.\")\n",
    "\n",
    "        # Check for proper heading structure\n",
    "        headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "        for i, heading in enumerate(headings):\n",
    "            if i > 0 and int(heading.name[1]) > int(headings[i-1].name[1]) + 1:\n",
    "                self.errors.append(\"Improper heading structure\")\n",
    "                self.suggestions.append(\"Ensure heading levels are properly nested without skipping levels.\")\n",
    "\n",
    "        # Check for ARIA roles\n",
    "        if not soup.find_all(attrs={\"role\": True}):\n",
    "            self.suggestions.append(\"Consider adding ARIA roles to improve accessibility.\")\n",
    "\n",
    "    def _compare_json_structure(self, dict1, dict2):\n",
    "        if type(dict1) != type(dict2):\n",
    "            if (isinstance(dict1, (int, float, str, bool)) and \n",
    "                isinstance(dict2, (int, float, str, bool))):\n",
    "                return True  # Allow type flexibility for leaf nodes\n",
    "            return False\n",
    "        if isinstance(dict1, dict):\n",
    "            return set(dict1.keys()) == set(dict2.keys()) and all(self._compare_json_structure(dict1[k], dict2[k]) for k in dict1)\n",
    "        if isinstance(dict1, list):\n",
    "            return len(dict1) == len(dict2) and all(self._compare_json_structure(v1, v2) for v1, v2 in zip(dict1, dict2))\n",
    "        return True\n",
    "\n",
    "    def _generate_json_schema(self, json_dict):\n",
    "        schema = {\"type\": \"object\", \"properties\": {}}\n",
    "        for key, value in json_dict.items():\n",
    "            if isinstance(value, dict):\n",
    "                schema[\"properties\"][key] = self._generate_json_schema(value)\n",
    "            elif isinstance(value, list):\n",
    "                schema[\"properties\"][key] = {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": self._generate_json_schema(value[0]) if value else {}\n",
    "                }\n",
    "            else:\n",
    "                schema[\"properties\"][key] = {\"type\": self._json_type(value)}\n",
    "        return schema\n",
    "\n",
    "    def _json_type(self, value):\n",
    "        if isinstance(value, int):\n",
    "            return \"integer\"\n",
    "        elif isinstance(value, float):\n",
    "            return \"number\"\n",
    "        elif isinstance(value, bool):\n",
    "            return \"boolean\"\n",
    "        elif isinstance(value, str):\n",
    "            return \"string\"\n",
    "        else:\n",
    "            return \"null\"\n",
    "\n",
    "    def _compare_xml_structure(self, elem1, elem2):\n",
    "        if elem1.tag != elem2.tag:\n",
    "            return False\n",
    "        if elem1.attrib != elem2.attrib:\n",
    "            return False\n",
    "        if len(elem1) != len(elem2):\n",
    "            return False\n",
    "        return all(self._compare_xml_structure(c1, c2) for c1, c2 in zip(elem1, elem2))\n",
    "\n",
    "    def _compare_xml_namespaces(self, elem1, elem2):\n",
    "        return elem1.nsmap == elem2.nsmap and all(self._compare_xml_namespaces(c1, c2) for c1, c2 in zip(elem1, elem2))\n",
    "\n",
    "    def get_feedback(self):\n",
    "        return {\n",
    "            \"errors\": self.errors,\n",
    "            \"suggestions\": self.suggestions\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML Validation: False\n",
      "Feedback: {'errors': ['HTML attribute mismatch', 'Image without alt text'], 'suggestions': ['Preserve all original HTML attributes, including their values.', 'Add descriptive alt text to all images for accessibility.', 'Consider adding ARIA roles to improve accessibility.']}\n",
      "\n",
      "JSON Validation: True\n",
      "Feedback: {'errors': [], 'suggestions': []}\n",
      "\n",
      "XML Validation: False\n",
      "Feedback: {'errors': ['Invalid XML format: XML declaration allowed only at the start of the document, line 2, column 10 (<string>, line 2)'], 'suggestions': ['Ensure the XML is well-formed with proper opening and closing tags.']}\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    validator = EnhancedStructureValidator()\n",
    "\n",
    "    # HTML example\n",
    "    original_html = \"\"\"\n",
    "    <html>\n",
    "    <head><title>Test</title></head>\n",
    "    <body>\n",
    "        <h1>Hello</h1>\n",
    "        <nav><a href=\"#\">Link</a></nav>\n",
    "        <img src=\"test.jpg\" alt=\"Test image\">\n",
    "        <p>World</p>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    reconstructed_html = \"\"\"\n",
    "    <html>\n",
    "    <head><title>Test</title></head>\n",
    "    <body>\n",
    "        <h1>Bonjour</h1>\n",
    "        <nav><a href=\"#\">Lien</a></nav>\n",
    "        <img src=\"test.jpg\">\n",
    "        <p>Monde</p>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    print(\"HTML Validation:\", validator.validate(original_html, reconstructed_html, 'html'))\n",
    "    print(\"Feedback:\", validator.get_feedback())\n",
    "\n",
    "    # JSON example\n",
    "    original_json = '{\"name\": \"John\", \"age\": 30, \"city\": {\"name\": \"New York\", \"population\": 8400000}}'\n",
    "    reconstructed_json = '{\"name\": \"Jean\", \"age\": 35, \"city\": {\"name\": \"Paris\", \"population\": 2161000}}'\n",
    "    print(\"\\nJSON Validation:\", validator.validate(original_json, reconstructed_json, 'json'))\n",
    "    print(\"Feedback:\", validator.get_feedback())\n",
    "\n",
    "    # XML example\n",
    "    original_xml = \"\"\"\n",
    "    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "    <root xmlns:x=\"http://example.com\">\n",
    "        <person>\n",
    "            <name>John</name>\n",
    "            <age>30</age>\n",
    "        </person>\n",
    "    </root>\n",
    "    \"\"\"\n",
    "    reconstructed_xml = \"\"\"\n",
    "    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "    <root xmlns:x=\"http://example.com\">\n",
    "        <person>\n",
    "            <name>Jean</name>\n",
    "            <age>35</age>\n",
    "        </person>\n",
    "    </root>\n",
    "    \"\"\"\n",
    "    print(\"\\nXML Validation:\", validator.validate(original_xml, reconstructed_xml, 'xml'))\n",
    "    print(\"Feedback:\", validator.get_feedback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
