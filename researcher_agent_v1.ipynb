{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9774aebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import TypedDict, Annotated, List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from tavily import TavilyClient\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d76de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchDepth(Enum):\n",
    "    BASIC = \"basic\"\n",
    "    ADVANCED = \"advanced\"\n",
    "\n",
    "@dataclass\n",
    "class SearchConfig:\n",
    "    \"\"\"Configuration for search operations\"\"\"\n",
    "    max_results: int = 5\n",
    "    search_depth: SearchDepth = SearchDepth.ADVANCED\n",
    "    enable_verification: bool = True\n",
    "    verification_threshold: float = 0.7\n",
    "    min_sources_for_verification: int = 3\n",
    "\n",
    "class VerificationResult(BaseModel):\n",
    "    \"\"\"Information verification results\"\"\"\n",
    "    consistency_score: float = Field(..., ge=0, le=1)\n",
    "    confidence_level: str  # \"high\", \"medium\", \"low\"\n",
    "    conflicting_claims: List[str] = []\n",
    "    supporting_sources: List[str] = []\n",
    "    verification_notes: List[str] = []\n",
    "    fact_checks: Dict[str, Any] = {}\n",
    "\n",
    "class SearchResponse(BaseModel):\n",
    "    \"\"\"Search response with verification\"\"\"\n",
    "    query: str\n",
    "    answer: str\n",
    "    tavily_answer: Optional[str] = None\n",
    "    source_count: int\n",
    "    search_results: Dict[str, Any]\n",
    "    verification: Optional[VerificationResult] = None\n",
    "    timestamp: datetime\n",
    "    duration_ms: int\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: Annotated[str, \"The user's search query\"]\n",
    "    search_results: Annotated[Dict, \"Search results from Tavily\"]\n",
    "    verification_result: Annotated[Optional[VerificationResult], \"Verification results\"]\n",
    "    final_answer: Annotated[str, \"Final answer to the user\"]\n",
    "    config: Annotated[SearchConfig, \"Search configuration\"]\n",
    "    start_time: Annotated[float, \"Request start time\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3938800",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InformationVerifier:\n",
    "    \"\"\"Verify information consistency across multiple sources\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "    \n",
    "    def verify_information(self, query: str, search_results: Dict, config: SearchConfig) -> VerificationResult:\n",
    "        \"\"\"Verify information consistency across sources\"\"\"\n",
    "        \n",
    "        if not config.enable_verification:\n",
    "            return VerificationResult(\n",
    "                consistency_score=0.5,\n",
    "                confidence_level=\"unknown\",\n",
    "                verification_notes=[\"Verification disabled\"]\n",
    "            )\n",
    "        \n",
    "        results = search_results.get(\"results\", [])\n",
    "        if len(results) < config.min_sources_for_verification:\n",
    "            return VerificationResult(\n",
    "                consistency_score=0.3,\n",
    "                confidence_level=\"low\",\n",
    "                verification_notes=[f\"Insufficient sources for verification (found {len(results)}, need {config.min_sources_for_verification})\"]\n",
    "            )\n",
    "        \n",
    "        try:\n",
    "            # Extract key facts from sources\n",
    "            facts_by_source = self._extract_facts_from_sources(query, results)\n",
    "            \n",
    "            # Analyze consistency\n",
    "            consistency_analysis = self._analyze_consistency(facts_by_source)\n",
    "            \n",
    "            # Evaluate source credibility\n",
    "            credibility_scores = self._evaluate_source_credibility(results)\n",
    "            \n",
    "            # Calculate overall consistency score\n",
    "            overall_score = self._calculate_consistency_score(consistency_analysis, credibility_scores)\n",
    "            \n",
    "            # Determine confidence level\n",
    "            confidence_level = self._determine_confidence_level(overall_score)\n",
    "            \n",
    "            return VerificationResult(\n",
    "                consistency_score=overall_score,\n",
    "                confidence_level=confidence_level,\n",
    "                conflicting_claims=consistency_analysis.get(\"inconsistent_facts\", []),\n",
    "                supporting_sources=[result.get(\"url\", \"\") for result in results[:3]],\n",
    "                verification_notes=self._generate_verification_notes(consistency_analysis, credibility_scores),\n",
    "                fact_checks=consistency_analysis\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            return VerificationResult(\n",
    "                consistency_score=0.4,\n",
    "                confidence_level=\"low\",\n",
    "                verification_notes=[f\"Verification failed: {str(e)}\"]\n",
    "            )\n",
    "    \n",
    "    def _extract_facts_from_sources(self, query: str, results: List[Dict]) -> Dict[str, List[str]]:\n",
    "        \"\"\"Extract key facts from each source\"\"\"\n",
    "        \n",
    "        fact_extraction_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"Extract key factual claims from the text that are related to the query.\n",
    "\n",
    "                Rules:\n",
    "                1. Extract only verifiable factual statements\n",
    "                2. Ignore opinions or speculation\n",
    "                3. Focus on facts directly related to the query\n",
    "                4. Return as a JSON list of strings\n",
    "                5. Keep facts concise and specific\n",
    "\n",
    "                Query: {query}\n",
    "                Text: {content}\n",
    "\n",
    "                Return format: [\"fact1\", \"fact2\", \"fact3\"]\"\"\"),\n",
    "                            (\"human\", \"Extract facts\")\n",
    "                        ])\n",
    "        \n",
    "        facts_by_source = {}\n",
    "        \n",
    "        for i, result in enumerate(results[:5]):\n",
    "            content = result.get(\"content\", \"\")[:800]  # Limit content\n",
    "            if not content.strip():\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                response = self.llm.invoke(\n",
    "                    fact_extraction_prompt.format_messages(\n",
    "                        query=query,\n",
    "                        content=content\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                facts_text = response.content.strip()\n",
    "                if facts_text.startswith(\"```json\"):\n",
    "                    facts_text = facts_text[7:-3].strip()\n",
    "                elif facts_text.startswith(\"```\"):\n",
    "                    facts_text = facts_text[3:-3].strip()\n",
    "                \n",
    "                facts = json.loads(facts_text)\n",
    "                facts_by_source[f\"source_{i}\"] = facts\n",
    "                \n",
    "            except Exception:\n",
    "                facts_by_source[f\"source_{i}\"] = []\n",
    "        \n",
    "        return facts_by_source\n",
    "    \n",
    "    def _analyze_consistency(self, facts_by_source: Dict[str, List[str]]) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze consistency across extracted facts\"\"\"\n",
    "        \n",
    "        all_facts = []\n",
    "        for facts in facts_by_source.values():\n",
    "            all_facts.extend(facts)\n",
    "        \n",
    "        if not all_facts:\n",
    "            return {\"consistent_facts\": [], \"inconsistent_facts\": [], \"unique_facts\": []}\n",
    "        \n",
    "        consistency_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"Analyze these facts for consistency and contradictions.\n",
    "\n",
    "                Instructions:\n",
    "                1. Group similar or related facts together\n",
    "                2. Identify contradictions or inconsistencies  \n",
    "                3. Note facts that appear across multiple sources\n",
    "                4. Identify unique facts from single sources\n",
    "\n",
    "                Facts: {facts}\n",
    "\n",
    "                Return JSON:\n",
    "                {{\n",
    "                    \"consistent_facts\": [\"facts supported by multiple sources\"],\n",
    "                    \"inconsistent_facts\": [\"contradictory facts\"],\n",
    "                    \"unique_facts\": [\"facts from single sources\"],\n",
    "                    \"confidence_notes\": [\"explanations\"]\n",
    "                }}\"\"\"),\n",
    "                            (\"human\", \"Analyze consistency\")\n",
    "                        ])\n",
    "        \n",
    "        try:\n",
    "            response = self.llm.invoke(\n",
    "                consistency_prompt.format_messages(facts=json.dumps(all_facts, indent=2))\n",
    "            )\n",
    "            \n",
    "            analysis_text = response.content.strip()\n",
    "            if analysis_text.startswith(\"```json\"):\n",
    "                analysis_text = analysis_text[7:-3].strip()\n",
    "            elif analysis_text.startswith(\"```\"):\n",
    "                analysis_text = analysis_text[3:-3].strip()\n",
    "            \n",
    "            return json.loads(analysis_text)\n",
    "            \n",
    "        except Exception:\n",
    "            return {\n",
    "                \"consistent_facts\": all_facts[:3],\n",
    "                \"inconsistent_facts\": [],\n",
    "                \"unique_facts\": [],\n",
    "                \"confidence_notes\": [\"Analysis failed\"]\n",
    "            }\n",
    "    \n",
    "    def _evaluate_source_credibility(self, results: List[Dict]) -> Dict[str, float]:\n",
    "        \"\"\"Simple source credibility scoring\"\"\"\n",
    "        credibility_scores = {}\n",
    "        \n",
    "        for i, result in enumerate(results):\n",
    "            score = 0.5  # Base score\n",
    "            url = result.get(\"url\", \"\").lower()\n",
    "            \n",
    "            # Domain-based scoring\n",
    "            if any(domain in url for domain in [\".edu\", \".gov\", \".org\"]):\n",
    "                score += 0.3\n",
    "            elif any(domain in url for domain in [\".com\", \".net\"]):\n",
    "                score += 0.1\n",
    "            \n",
    "            # Known credible sources\n",
    "            credible_domains = [\n",
    "                \"wikipedia.org\", \"pubmed.ncbi.nlm.nih.gov\", \"who.int\", \n",
    "                \"cdc.gov\", \"nih.gov\", \"reuters.com\", \"bbc.com\", \"nature.com\"\n",
    "            ]\n",
    "            \n",
    "            if any(domain in url for domain in credible_domains):\n",
    "                score += 0.2\n",
    "            \n",
    "            # Content quality\n",
    "            if len(result.get(\"content\", \"\")) > 500:\n",
    "                score += 0.1\n",
    "            \n",
    "            # Tavily relevance score\n",
    "            tavily_score = result.get(\"score\", 0)\n",
    "            score += min(tavily_score * 0.1, 0.1)\n",
    "            \n",
    "            credibility_scores[f\"source_{i}\"] = min(max(score, 0.0), 1.0)\n",
    "        \n",
    "        return credibility_scores\n",
    "    \n",
    "    def _calculate_consistency_score(self, consistency_analysis: Dict, credibility_scores: Dict) -> float:\n",
    "        \"\"\"Calculate overall consistency score\"\"\"\n",
    "        \n",
    "        consistent_facts = len(consistency_analysis.get(\"consistent_facts\", []))\n",
    "        inconsistent_facts = len(consistency_analysis.get(\"inconsistent_facts\", []))\n",
    "        \n",
    "        if consistent_facts + inconsistent_facts == 0:\n",
    "            consistency_ratio = 0.5\n",
    "        else:\n",
    "            consistency_ratio = consistent_facts / (consistent_facts + inconsistent_facts)\n",
    "        \n",
    "        avg_credibility = sum(credibility_scores.values()) / len(credibility_scores) if credibility_scores else 0.5\n",
    "        conflict_penalty = min(inconsistent_facts * 0.1, 0.3)\n",
    "        \n",
    "        final_score = (consistency_ratio * 0.6 + avg_credibility * 0.4) - conflict_penalty\n",
    "        return min(max(final_score, 0.0), 1.0)\n",
    "    \n",
    "    def _determine_confidence_level(self, score: float) -> str:\n",
    "        \"\"\"Determine confidence level\"\"\"\n",
    "        if score >= 0.8:\n",
    "            return \"high\"\n",
    "        elif score >= 0.6:\n",
    "            return \"medium\"\n",
    "        else:\n",
    "            return \"low\"\n",
    "    \n",
    "    def _generate_verification_notes(self, consistency_analysis: Dict, credibility_scores: Dict) -> List[str]:\n",
    "        \"\"\"Generate verification notes\"\"\"\n",
    "        notes = []\n",
    "        \n",
    "        consistent_count = len(consistency_analysis.get(\"consistent_facts\", []))\n",
    "        inconsistent_count = len(consistency_analysis.get(\"inconsistent_facts\", []))\n",
    "        \n",
    "        notes.append(f\"Found {consistent_count} consistent facts across sources\")\n",
    "        \n",
    "        if inconsistent_count > 0:\n",
    "            notes.append(f\"Detected {inconsistent_count} potential contradictions\")\n",
    "        \n",
    "        avg_credibility = sum(credibility_scores.values()) / len(credibility_scores) if credibility_scores else 0\n",
    "        notes.append(f\"Average source credibility: {avg_credibility:.2f}\")\n",
    "        \n",
    "        return notes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64646d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchAgent:\n",
    "    \"\"\"Simple search agent with information verification\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize LLM and clients\n",
    "        self.llm = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-1.5-pro\",\n",
    "            temperature=0.1,\n",
    "            google_api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    "        )\n",
    "        \n",
    "        self.tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "        self.verifier = InformationVerifier(self.llm)\n",
    "        \n",
    "        # Create the graph\n",
    "        self.graph = self._create_graph()\n",
    "    \n",
    "    def _search_node(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"Execute Tavily search\"\"\"\n",
    "        query = state[\"query\"]\n",
    "        config = state[\"config\"]\n",
    "        \n",
    "        try:\n",
    "            search_results = self.tavily_client.search(\n",
    "                query=query,\n",
    "                search_depth=config.search_depth.value,\n",
    "                max_results=config.max_results,\n",
    "                include_answer=True,\n",
    "                include_raw_content=False\n",
    "            )\n",
    "            \n",
    "            state[\"search_results\"] = search_results\n",
    "            print(f\"✓ Search completed: {len(search_results.get('results', []))} sources found\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Search failed: {e}\")\n",
    "            state[\"search_results\"] = {\"error\": str(e), \"results\": [], \"answer\": \"\"}\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def _verify_node(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"Verify information consistency\"\"\"\n",
    "        \n",
    "        query = state[\"query\"]\n",
    "        search_results = state[\"search_results\"]\n",
    "        config = state[\"config\"]\n",
    "        \n",
    "        try:\n",
    "            verification_result = self.verifier.verify_information(query, search_results, config)\n",
    "            state[\"verification_result\"] = verification_result\n",
    "            \n",
    "            print(f\"✓ Verification completed: {verification_result.confidence_level} confidence ({verification_result.consistency_score:.2f})\")\n",
    "            \n",
    "            if verification_result.conflicting_claims:\n",
    "                print(f\"⚠ Conflicts detected: {len(verification_result.conflicting_claims)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Verification failed: {e}\")\n",
    "            state[\"verification_result\"] = VerificationResult(\n",
    "                consistency_score=0.5,\n",
    "                confidence_level=\"unknown\",\n",
    "                verification_notes=[f\"Verification failed: {e}\"]\n",
    "            )\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def _answer_node(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"Generate final answer with verification context\"\"\"\n",
    "        \n",
    "        query = state[\"query\"]\n",
    "        search_results = state[\"search_results\"]\n",
    "        verification_result = state.get(\"verification_result\")\n",
    "        \n",
    "        # Format search results\n",
    "        if \"error\" in search_results:\n",
    "            results_text = f\"Search Error: {search_results['error']}\"\n",
    "        else:\n",
    "            results_text = self._format_search_results(search_results)\n",
    "        \n",
    "        # Add verification context\n",
    "        verification_context = \"\"\n",
    "        if verification_result:\n",
    "            verification_context = f\"\"\"\n",
    "            VERIFICATION ANALYSIS:\n",
    "            - Consistency Score: {verification_result.consistency_score:.2f}\n",
    "            - Confidence Level: {verification_result.confidence_level}\n",
    "            - Sources Analyzed: {len(verification_result.supporting_sources)}\n",
    "\n",
    "            {f\"⚠ CONFLICTS DETECTED: {verification_result.conflicting_claims}\" if verification_result.conflicting_claims else \"✓ No major conflicts detected\"}\n",
    "\n",
    "            Notes: {'; '.join(verification_result.verification_notes)}\n",
    "            \"\"\"\n",
    "                    \n",
    "            answer_prompt = ChatPromptTemplate.from_messages([\n",
    "                        (\"system\", \"\"\"You are an AI research assistant with fact-checking capabilities. Provide accurate answers based on search results and verification analysis.\n",
    "\n",
    "            IMPORTANT GUIDELINES:\n",
    "            1. Use search results as your primary information source\n",
    "            2. Consider the verification analysis when forming your answer\n",
    "            3. If consistency score is LOW (< 0.6), mention uncertainty clearly\n",
    "            4. If conflicts are detected, acknowledge them in your response\n",
    "            5. Cite sources when possible\n",
    "            6. Be transparent about limitations\n",
    "\n",
    "            SEARCH RESULTS:\n",
    "            {search_results}\n",
    "\n",
    "            {verification_context}\n",
    "\n",
    "            Provide a comprehensive answer that incorporates the verification insights.\"\"\"),\n",
    "                        (\"human\", \"Question: {query}\")\n",
    "                    ])\n",
    "        \n",
    "        try:\n",
    "            response = self.llm.invoke(\n",
    "                answer_prompt.format_messages(\n",
    "                    query=query,\n",
    "                    search_results=results_text,\n",
    "                    verification_context=verification_context\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            state[\"final_answer\"] = response.content\n",
    "            print(\"✓ Answer generated with verification context\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Answer generation failed: {str(e)}\"\n",
    "            state[\"final_answer\"] = error_msg\n",
    "            print(f\"✗ Answer generation failed: {e}\")\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def _format_search_results(self, search_results: Dict) -> str:\n",
    "        \"\"\"Format search results for LLM\"\"\"\n",
    "        results_text = \"\"\n",
    "        \n",
    "        # Add Tavily AI answer\n",
    "        if search_results.get(\"answer\"):\n",
    "            results_text += f\"AI SUMMARY: {search_results['answer']}\\n\\n\"\n",
    "        \n",
    "        # Add search results\n",
    "        if search_results.get(\"results\"):\n",
    "            results_text += \"SOURCES:\\n\"\n",
    "            for i, result in enumerate(search_results[\"results\"], 1):\n",
    "                results_text += f\"{i}. {result.get('title', 'Untitled')}\\n\"\n",
    "                results_text += f\"   URL: {result.get('url', 'No URL')}\\n\"\n",
    "                results_text += f\"   Content: {result.get('content', 'No content')[:300]}...\\n\\n\"\n",
    "        \n",
    "        return results_text\n",
    "    \n",
    "    def _create_graph(self) -> StateGraph:\n",
    "        \"\"\"Create the workflow: search → verify → answer\"\"\"\n",
    "        workflow = StateGraph(AgentState)\n",
    "        \n",
    "        workflow.add_node(\"search\", self._search_node)\n",
    "        workflow.add_node(\"verify\", self._verify_node)\n",
    "        workflow.add_node(\"answer\", self._answer_node)\n",
    "        \n",
    "        workflow.set_entry_point(\"search\")\n",
    "        workflow.add_edge(\"search\", \"verify\")\n",
    "        workflow.add_edge(\"verify\", \"answer\")\n",
    "        workflow.add_edge(\"answer\", END)\n",
    "        \n",
    "        return workflow.compile()\n",
    "    \n",
    "    def search(self, query: str, config: Optional[SearchConfig] = None) -> SearchResponse:\n",
    "        \"\"\"Main search method with verification\"\"\"\n",
    "        \n",
    "        start_time = time.time()\n",
    "        search_config = config or SearchConfig()\n",
    "        \n",
    "        print(f\"\\n🔍 Searching: {query}\")\n",
    "        print(f\"📊 Verification: {'enabled' if search_config.enable_verification else 'disabled'}\")\n",
    "        \n",
    "        # Prepare initial state\n",
    "        initial_state = {\n",
    "            \"query\": query,\n",
    "            \"search_results\": {},\n",
    "            \"verification_result\": None,\n",
    "            \"final_answer\": \"\",\n",
    "            \"config\": search_config,\n",
    "            \"start_time\": start_time\n",
    "        }\n",
    "        \n",
    "        # Execute workflow\n",
    "        final_state = self.graph.invoke(initial_state)\n",
    "        \n",
    "        # Calculate duration\n",
    "        duration_ms = int((time.time() - start_time) * 1000)\n",
    "        \n",
    "        # Create response\n",
    "        response = SearchResponse(\n",
    "            query=query,\n",
    "            answer=final_state.get(\"final_answer\", \"\"),\n",
    "            tavily_answer=final_state.get(\"search_results\", {}).get(\"answer\"),\n",
    "            source_count=len(final_state.get(\"search_results\", {}).get(\"results\", [])),\n",
    "            search_results=final_state.get(\"search_results\", {}),\n",
    "            verification=final_state.get(\"verification_result\"),\n",
    "            timestamp=datetime.now(),\n",
    "            duration_ms=duration_ms\n",
    "        )\n",
    "        \n",
    "        print(f\"⏱ Completed in {duration_ms}ms\")\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83582ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 Searching: What are the health benefits of intermittent fasting?\n",
      "📊 Verification: enabled\n",
      "✗ Search failed: 403 Client Error: Forbidden for url: https://api.tavily.com/search\n",
      "✓ Verification completed: low confidence (0.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      "violations {\n",
      "}\n",
      "violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 33\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Answer generation failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      "violations {\n",
      "}\n",
      "violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 31\n",
      "}\n",
      "]\n",
      "⏱ Completed in 4728ms\n",
      "\n",
      "📋 RESULTS SUMMARY:\n",
      "Query: What are the health benefits of intermittent fasting?\n",
      "Sources: 0\n",
      "Verification: low confidence (0.30)\n",
      "\n",
      "💬 ANSWER:\n",
      "Answer generation failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "}\n",
      "violations {\n",
      "}\n",
      "violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3...\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize agent\n",
    "    agent = SearchAgent()\n",
    "    \n",
    "    # Example searches with verification\n",
    "    queries = [\n",
    "        \"What are the health benefits of intermittent fasting?\",\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        \n",
    "        # Search with verification enabled\n",
    "        result = agent.search(query, SearchConfig(enable_verification=True))\n",
    "        \n",
    "        print(f\"\\n📋 RESULTS SUMMARY:\")\n",
    "        print(f\"Query: {result.query}\")\n",
    "        print(f\"Sources: {result.source_count}\")\n",
    "        \n",
    "        if result.verification:\n",
    "            print(f\"Verification: {result.verification.confidence_level} confidence ({result.verification.consistency_score:.2f})\")\n",
    "            if result.verification.conflicting_claims:\n",
    "                print(f\"Conflicts: {len(result.verification.conflicting_claims)} detected\")\n",
    "        \n",
    "        print(f\"\\n💬 ANSWER:\")\n",
    "        print(result.answer[:400] + \"...\" if len(result.answer) > 400 else result.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27287f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".cvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
